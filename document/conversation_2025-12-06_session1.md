# Medium æ•°æ®é›†æ”¶é›†æ“ä½œæŒ‡å—

**æ—¥æœŸ**: 2025-12-06
**ç›®çš„**: ä½¿ç”¨è®­ç»ƒåˆ° 50,000 æ­¥çš„ SAC+GeMS æ¨¡å‹æ”¶é›† Medium è´¨é‡çš„ç¦»çº¿æ•°æ®é›†

---

## ä¸€ã€è®­ç»ƒé˜¶æ®µï¼ˆå·²å®Œæˆï¼‰

### 1.1 è®­ç»ƒé…ç½®

**è®­ç»ƒè„šæœ¬**: `scripts/batch_runs/run_medium_collection_training.sh`

**å…³é”®å‚æ•°**:
- `--max_steps=100000` - è®­ç»ƒ 100k æ­¥
- `--save_every_n_steps=50000` - åœ¨ç¬¬ 50,000 æ­¥ä¿å­˜æ¨¡å‹
- `--check_val_every_n_epoch=1000` - æ¯ 1000 ä¸ª episode éªŒè¯ä¸€æ¬¡
- `--lambda_KL=1.0`, `--lambda_click=0.5` - è®ºæ–‡å®˜æ–¹å‚æ•°

**è®­ç»ƒç¯å¢ƒ** (6ä¸ª):
1. `diffuse_topdown` - Diffuse ç”¨æˆ· + Top-down ç‚¹å‡»æ¨¡å‹
2. `diffuse_mix` - Diffuse ç”¨æˆ· + Mix ç‚¹å‡»æ¨¡å‹
3. `diffuse_divpen` - Diffuse ç”¨æˆ· + Mix ç‚¹å‡»æ¨¡å‹ + é«˜å¤šæ ·æ€§æƒ©ç½š
4. `focused_topdown` - Focused ç”¨æˆ· + Top-down ç‚¹å‡»æ¨¡å‹
5. `focused_mix` - Focused ç”¨æˆ· + Mix ç‚¹å‡»æ¨¡å‹
6. `focused_divpen` - Focused ç”¨æˆ· + Mix ç‚¹å‡»æ¨¡å‹ + é«˜å¤šæ ·æ€§æƒ©ç½š

**æ¨¡å‹ä¿å­˜ä½ç½®**:
```
checkpoints/online_rl/{env_name}/
â”œâ”€â”€ SAC+GeMS_Medium_GeMS_{env}_..._best.ckpt      # æœ€ä½³æ¨¡å‹
â”œâ”€â”€ SAC+GeMS_Medium_GeMS_{env}_..._step50000.ckpt # 50kæ­¥æ¨¡å‹ â­ ç”¨äºæ•°æ®æ”¶é›†
â””â”€â”€ SAC+GeMS_Medium_GeMS_{env}_..._last.ckpt      # æœ€ç»ˆæ¨¡å‹
```

### 1.2 è®­ç»ƒç›‘æ§

**æŸ¥çœ‹è®­ç»ƒè¿›åº¦**:
```bash
# æŸ¥çœ‹æ‰€æœ‰ç¯å¢ƒçš„æœ€æ–°è¿›åº¦
grep 'Training Step' experiments/logs/log_58407201/SAC_GeMS/medium_collection_20251206/*.log | tail -20

# æŸ¥çœ‹éªŒè¯ç»“æœ
grep 'VALIDATION' experiments/logs/log_58407201/SAC_GeMS/medium_collection_20251206/*.log | tail -20

# å®æ—¶ç›‘æ§æŸä¸ªç¯å¢ƒ
tail -f experiments/logs/log_58407201/SAC_GeMS/medium_collection_20251206/diffuse_topdown_KL1.0_click0.5_20251206.log
```

**ç¡®è®¤è®­ç»ƒå®Œæˆ**:
```bash
# æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ 50,000 æ­¥å¹¶ä¿å­˜äº†æ¨¡å‹
ls -lh checkpoints/online_rl/*/SAC+GeMS_Medium_*_step50000.ckpt
```

é¢„æœŸè¾“å‡ºï¼š6 ä¸ªç¯å¢ƒå„æœ‰ä¸€ä¸ª `*_step50000.ckpt` æ–‡ä»¶ã€‚

---

## äºŒã€æ•°æ®æ”¶é›†é˜¶æ®µï¼ˆå¾…æ‰§è¡Œï¼‰

### 2.1 å“²å­¦ï¼šè®­ç»ƒå½’è®­ç»ƒï¼Œå­˜å‚¨å½’å­˜å‚¨ï¼Œå†³ç­–åœ¨äºº

**æ ¸å¿ƒåŸåˆ™**:
1. **è®­ç»ƒå½’è®­ç»ƒ**: æ‰€æœ‰æ¨¡å‹ç»Ÿä¸€ä¿å­˜åˆ° `checkpoints/online_rl/{env}/`ï¼Œå¸¦æœ‰æ˜ç¡®çš„æ­¥æ•°æ ‡è®°
2. **å­˜å‚¨å½’å­˜å‚¨**: æ•°æ®æ”¶é›†è„šæœ¬ä»æ ‡å‡†ä½ç½®è¯»å–æ¨¡å‹ï¼Œæ”¶é›†çš„æ•°æ®ä¿å­˜åˆ°æ ‡å‡†ä½ç½®
3. **å†³ç­–åœ¨äºº**: äººå·¥æ£€æŸ¥æ¨¡å‹è´¨é‡ï¼Œå†³å®šæ˜¯å¦ä½¿ç”¨è¯¥æ¨¡å‹æ”¶é›†æ•°æ®

### 2.2 æ¨¡å‹è´¨é‡æ£€æŸ¥ï¼ˆå¿…é¡»æ­¥éª¤ï¼‰

åœ¨å¼€å§‹æ•°æ®æ”¶é›†å‰ï¼Œ**å¿…é¡»**æ£€æŸ¥æ¨¡å‹è´¨é‡ï¼š

#### æ­¥éª¤ 1: æŸ¥çœ‹è®­ç»ƒæ›²çº¿

è®¿é—® SwanLab é¡¹ç›®æŸ¥çœ‹è®­ç»ƒæ›²çº¿ï¼š
```
https://swanlab.cn/@Cliff/GeMS_RL_Training_202512
```

**æ£€æŸ¥æŒ‡æ ‡**:
- `train_reward`: è®­ç»ƒ reward æ˜¯å¦ç¨³å®šä¸Šå‡
- `val_reward`: éªŒè¯ reward æ˜¯å¦è¾¾åˆ°åˆç†æ°´å¹³
- å¯¹æ¯” 6 ä¸ªç¯å¢ƒçš„è¡¨ç°ï¼Œç¡®è®¤æ²¡æœ‰å¼‚å¸¸

#### æ­¥éª¤ 2: æŸ¥çœ‹æ—¥å¿—ä¸­çš„éªŒè¯ç»“æœ

```bash
# æŸ¥çœ‹ Step 49999 é™„è¿‘çš„éªŒè¯ç»“æœ
grep -A 5 "VALIDATION @ Step 49999" experiments/logs/log_58407201/SAC_GeMS/medium_collection_20251206/*.log
```

**é¢„æœŸç»“æœ**:
- `Mean Reward`: åº”è¯¥æ˜¾è‘—é«˜äºåˆå§‹å€¼ï¼ˆStep 0 çš„ rewardï¼‰
- ä¸åŒç¯å¢ƒçš„ reward èŒƒå›´ï¼š
  - Diffuse ç¯å¢ƒ: é€šå¸¸è¾ƒä½ï¼ˆç”¨æˆ·å…´è¶£åˆ†æ•£ï¼‰
  - Focused ç¯å¢ƒ: é€šå¸¸è¾ƒé«˜ï¼ˆç”¨æˆ·å…´è¶£é›†ä¸­ï¼‰

#### æ­¥éª¤ 3: ç¡®è®¤æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§

```bash
# æ£€æŸ¥æ‰€æœ‰ 50k æ­¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ä¸”å¤§å°åˆç†
for env in diffuse_topdown diffuse_mix diffuse_divpen focused_topdown focused_mix focused_divpen; do
    echo "=== $env ==="
    ls -lh checkpoints/online_rl/$env/*_step50000.ckpt
done
```

**é¢„æœŸ**: æ¯ä¸ªæ–‡ä»¶å¤§å°åº”è¯¥ç›¸ä¼¼ï¼ˆçº¦å‡ ç™¾ MBï¼‰ï¼Œå¦‚æœæŸä¸ªæ–‡ä»¶æ˜æ˜¾åå°æˆ–ä¸º 0ï¼Œè¯´æ˜ä¿å­˜å¤±è´¥ã€‚

### 2.3 æ•°æ®æ”¶é›†è„šæœ¬å‡†å¤‡

#### åˆ›å»ºæ•°æ®æ”¶é›†è„šæœ¬

åˆ›å»ºæ–‡ä»¶ï¼š`scripts/batch_runs/collect_medium_data.sh`

```bash
#!/bin/bash

# =================================================================
# Medium æ•°æ®é›†æ”¶é›†è„šæœ¬
# =================================================================
# åŠŸèƒ½ï¼š
# 1. ä½¿ç”¨è®­ç»ƒåˆ° 50k æ­¥çš„æ¨¡å‹æ”¶é›† Medium è´¨é‡æ•°æ®
# 2. ä¸º 6 ä¸ªç¯å¢ƒå„æ”¶é›† 10,000 æ¡è½¨è¿¹
# 3. æ•°æ®ä¿å­˜åˆ° data/offline_datasets/medium/
# =================================================================

# 0. æ¿€æ´» conda ç¯å¢ƒ
source ~/miniconda3/etc/profile.d/conda.sh
conda activate gems

# 1. åŸºç¡€é…ç½®
GPU_IDS=(1 2 3)
SEED=58407201
NUM_TRAJECTORIES=10000  # æ¯ä¸ªç¯å¢ƒæ”¶é›†çš„è½¨è¿¹æ•°
EPISODE_LENGTH=100

# 2. å®šä¹‰ç¯å¢ƒåˆ—è¡¨
ENVS=(
    "diffuse_topdown"
    "diffuse_mix"
    "diffuse_divpen"
    "focused_topdown"
    "focused_mix"
    "focused_divpen"
)

# 3. æ•°æ®ä¿å­˜ç›®å½•
DATA_BASE_DIR="/data/liyuefeng/offline-slate-rl/data/offline_datasets/medium"
mkdir -p ${DATA_BASE_DIR}

# 4. æ—¥å¿—ç›®å½•
LOG_BASE_DIR="/data/liyuefeng/offline-slate-rl/experiments/logs/data_collection/medium_$(date +%Y%m%d)"
mkdir -p ${LOG_BASE_DIR}

echo "=== å¼€å§‹æ”¶é›† Medium æ•°æ®é›† ==="
echo "=== æ•°æ®å°†ä¿å­˜åˆ°: ${DATA_BASE_DIR}/ ==="
echo "=== æ—¥å¿—å°†ä¿å­˜åˆ°: ${LOG_BASE_DIR}/ ==="
echo ""

# 5. å¾ªç¯æ”¶é›†æ•°æ®
for i in "${!ENVS[@]}"; do
    ENV=${ENVS[$i]}

    # è‡ªåŠ¨åˆ†é… GPU
    GPU_IDX=$((i % 3))
    GPU_ID=${GPU_IDS[$GPU_IDX]}

    # ç¡®å®š Click Model
    if [[ "$ENV" == *"topdown"* ]]; then
        CLICK_MODEL="tdPBM"
    else
        CLICK_MODEL="mixPBM"
    fi

    # ç¡®å®š Diversity Penalty
    if [[ "$ENV" == *"divpen"* ]]; then
        DIV_PENALTY=3.0
    else
        DIV_PENALTY=1.0
    fi

    # ç¡®å®š Environment Embeddings
    if [[ "$ENV" == *"diffuse"* ]]; then
        ENV_EMBEDDS="item_embeddings_diffuse.pt"
    else
        ENV_EMBEDDS="item_embeddings_focused.pt"
    fi

    # æ¨¡å‹è·¯å¾„ï¼ˆ50k æ­¥æ¨¡å‹ï¼‰
    MODEL_PATH="checkpoints/online_rl/${ENV}/SAC+GeMS_Medium_GeMS_${ENV}_agentseed${SEED}_gamma0.8_step50000.ckpt"

    # æ•°æ®ä¿å­˜è·¯å¾„
    DATA_OUTPUT="${DATA_BASE_DIR}/${ENV}_medium_${NUM_TRAJECTORIES}traj.pkl"

    # æ—¥å¿—æ–‡ä»¶
    LOG_FILE="${LOG_BASE_DIR}/${ENV}_collection.log"

    echo "----------------------------------------------------------------"
    echo "æ”¶é›†æ•°æ®: ${ENV}"
    echo "  - GPU: ${GPU_ID}"
    echo "  - Model: ${MODEL_PATH}"
    echo "  - Output: ${DATA_OUTPUT}"
    echo "  - Trajectories: ${NUM_TRAJECTORIES}"
    echo "  - Log: ${LOG_FILE}"
    echo "----------------------------------------------------------------"

    # æ‰§è¡Œæ•°æ®æ”¶é›†å‘½ä»¤
    CUDA_VISIBLE_DEVICES=${GPU_ID} nohup python -u scripts/collect_offline_data.py \
        --agent=SAC \
        --belief=GRU \
        --ranker=GeMS \
        --item_embedds=scratch \
        --env_name=topics \
        --device=cuda \
        --seed=${SEED} \
        --ranker_seed=${SEED} \
        --model_checkpoint=${MODEL_PATH} \
        --num_trajectories=${NUM_TRAJECTORIES} \
        --episode_length=${EPISODE_LENGTH} \
        --output_path=${DATA_OUTPUT} \
        --latent_dim=32 \
        --lambda_KL=1.0 \
        --lambda_click=0.5 \
        --lambda_prior=0.0 \
        --ranker_embedds=scratch \
        --ranker_sample=False \
        --ranker_dataset=${ENV} \
        --click_model=${CLICK_MODEL} \
        --env_embedds=${ENV_EMBEDDS} \
        --diversity_penalty=${DIV_PENALTY} \
        --belief_state_dim=20 \
        --item_embedd_dim=20 \
        --num_items=1000 \
        --boredom_threshold=5 \
        --recent_items_maxlen=10 \
        --boredom_moving_window=5 \
        --env_omega=0.9 \
        --short_term_boost=1.0 \
        --env_offset=0.28 \
        --env_slope=100 \
        --diversity_threshold=4 \
        --topic_size=2 \
        --num_topics=10 \
        --beliefs actor critic \
        > "${LOG_FILE}" 2>&1 &

    sleep 2
done

echo ""
echo "ğŸ‰ æ‰€æœ‰æ•°æ®æ”¶é›†ä»»åŠ¡å·²å¯åŠ¨!"
echo "ğŸ“ æ•°æ®ç›®å½•: ${DATA_BASE_DIR}/"
echo "ğŸ“ æ—¥å¿—ç›®å½•: ${LOG_BASE_DIR}/"
echo ""
echo "ç›‘æ§å‘½ä»¤:"
echo "  - tail -f ${LOG_BASE_DIR}/*.log          # æŸ¥çœ‹æ”¶é›†æ—¥å¿—"
echo "  - ls -lh ${DATA_BASE_DIR}/               # æŸ¥çœ‹å·²æ”¶é›†çš„æ•°æ®æ–‡ä»¶"
echo ""
```

**æ³¨æ„**:
1. è„šæœ¬ä¸­çš„ `MODEL_PATH` éœ€è¦æ ¹æ®å®é™…çš„æ–‡ä»¶åæ ¼å¼è°ƒæ•´
2. `scripts/collect_offline_data.py` éœ€è¦ç¡®è®¤æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨éœ€è¦åˆ›å»º

### 2.4 æ‰§è¡Œæ•°æ®æ”¶é›†

#### æ­¥éª¤ 1: èµ‹äºˆè„šæœ¬æ‰§è¡Œæƒé™

```bash
chmod +x scripts/batch_runs/collect_medium_data.sh
```

#### æ­¥éª¤ 2: å¯åŠ¨æ•°æ®æ”¶é›†

```bash
cd /data/liyuefeng/offline-slate-rl
bash scripts/batch_runs/collect_medium_data.sh
```

#### æ­¥éª¤ 3: ç›‘æ§æ•°æ®æ”¶é›†è¿›åº¦

```bash
# æŸ¥çœ‹å®æ—¶æ—¥å¿—
tail -f experiments/logs/data_collection/medium_20251206/*.log

# æŸ¥çœ‹å·²æ”¶é›†çš„æ•°æ®æ–‡ä»¶
ls -lh data/offline_datasets/medium/

# æ£€æŸ¥æ”¶é›†è¿›åº¦ï¼ˆå¦‚æœæ—¥å¿—ä¸­æœ‰è¿›åº¦ä¿¡æ¯ï¼‰
grep -i "progress\|trajectory\|collected" experiments/logs/data_collection/medium_20251206/*.log
```

### 2.5 æ•°æ®è´¨é‡éªŒè¯

æ•°æ®æ”¶é›†å®Œæˆåï¼Œ**å¿…é¡»**éªŒè¯æ•°æ®è´¨é‡ï¼š

#### æ­¥éª¤ 1: æ£€æŸ¥æ•°æ®æ–‡ä»¶å®Œæ•´æ€§

```bash
# æ£€æŸ¥æ‰€æœ‰æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
for env in diffuse_topdown diffuse_mix diffuse_divpen focused_topdown focused_mix focused_divpen; do
    echo "=== $env ==="
    ls -lh data/offline_datasets/medium/${env}_medium_10000traj.pkl
done
```

**é¢„æœŸ**: æ¯ä¸ªæ–‡ä»¶å¤§å°åº”è¯¥ç›¸ä¼¼ä¸”åˆç†ï¼ˆå–å†³äºè½¨è¿¹é•¿åº¦å’Œç‰¹å¾ç»´åº¦ï¼‰ã€‚

#### æ­¥éª¤ 2: åŠ è½½å¹¶æ£€æŸ¥æ•°æ®å†…å®¹

åˆ›å»ºéªŒè¯è„šæœ¬ `scripts/verify_medium_data.py`:

```python
import pickle
import numpy as np
from pathlib import Path

def verify_dataset(data_path):
    """éªŒè¯æ•°æ®é›†çš„å®Œæ•´æ€§å’Œè´¨é‡"""
    print(f"\n{'='*60}")
    print(f"éªŒè¯æ•°æ®é›†: {data_path.name}")
    print(f"{'='*60}")

    # åŠ è½½æ•°æ®
    with open(data_path, 'rb') as f:
        data = pickle.load(f)

    # æ£€æŸ¥æ•°æ®ç»“æ„
    print(f"æ•°æ®ç±»å‹: {type(data)}")

    if isinstance(data, dict):
        print(f"æ•°æ®å­—æ®µ: {list(data.keys())}")

        # æ£€æŸ¥è½¨è¿¹æ•°é‡
        if 'observations' in data:
            num_traj = len(data['observations'])
            print(f"è½¨è¿¹æ•°é‡: {num_traj}")

        # æ£€æŸ¥ reward åˆ†å¸ƒ
        if 'rewards' in data:
            rewards = np.concatenate(data['rewards'])
            print(f"Reward ç»Ÿè®¡:")
            print(f"  - Mean: {rewards.mean():.4f}")
            print(f"  - Std: {rewards.std():.4f}")
            print(f"  - Min: {rewards.min():.4f}")
            print(f"  - Max: {rewards.max():.4f}")

        # æ£€æŸ¥è½¨è¿¹é•¿åº¦
        if 'observations' in data:
            traj_lengths = [len(obs) for obs in data['observations']]
            print(f"è½¨è¿¹é•¿åº¦ç»Ÿè®¡:")
            print(f"  - Mean: {np.mean(traj_lengths):.2f}")
            print(f"  - Min: {np.min(traj_lengths)}")
            print(f"  - Max: {np.max(traj_lengths)}")

    print(f"âœ… æ•°æ®é›†éªŒè¯å®Œæˆ")
    return True

if __name__ == "__main__":
    data_dir = Path("data/offline_datasets/medium")

    envs = [
        "diffuse_topdown",
        "diffuse_mix",
        "diffuse_divpen",
        "focused_topdown",
        "focused_mix",
        "focused_divpen"
    ]

    for env in envs:
        data_path = data_dir / f"{env}_medium_10000traj.pkl"
        if data_path.exists():
            verify_dataset(data_path)
        else:
            print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
```

è¿è¡ŒéªŒè¯ï¼š
```bash
python scripts/verify_medium_data.py
```

#### æ­¥éª¤ 3: å¯¹æ¯” Medium æ•°æ®ä¸ Random æ•°æ®

å¦‚æœå·²æœ‰ Random æ•°æ®ï¼Œå¯¹æ¯” reward åˆ†å¸ƒï¼š

```bash
# Medium æ•°æ®çš„ reward åº”è¯¥æ˜¾è‘—é«˜äº Random æ•°æ®
# å¯ä»¥é€šè¿‡éªŒè¯è„šæœ¬è¾“å‡ºçš„ç»Ÿè®¡ä¿¡æ¯è¿›è¡Œå¯¹æ¯”
```

---

## ä¸‰ã€æ•°æ®ç»„ç»‡ä¸å½’æ¡£

### 3.1 æ•°æ®ç›®å½•ç»“æ„

```
data/offline_datasets/
â”œâ”€â”€ random/                          # Random ç­–ç•¥æ•°æ®
â”‚   â”œâ”€â”€ diffuse_topdown_random_10000traj.pkl
â”‚   â””â”€â”€ ...
â”œâ”€â”€ medium/                          # Medium ç­–ç•¥æ•°æ® â­ æ–°æ”¶é›†
â”‚   â”œâ”€â”€ diffuse_topdown_medium_10000traj.pkl
â”‚   â”œâ”€â”€ diffuse_mix_medium_10000traj.pkl
â”‚   â”œâ”€â”€ diffuse_divpen_medium_10000traj.pkl
â”‚   â”œâ”€â”€ focused_topdown_medium_10000traj.pkl
â”‚   â”œâ”€â”€ focused_mix_medium_10000traj.pkl
â”‚   â””â”€â”€ focused_divpen_medium_10000traj.pkl
â””â”€â”€ expert/                          # Expert ç­–ç•¥æ•°æ®ï¼ˆæœªæ¥ï¼‰
    â””â”€â”€ ...
```

### 3.2 å…ƒæ•°æ®è®°å½•

åˆ›å»º `data/offline_datasets/medium/README.md`:

```markdown
# Medium Dataset

**æ”¶é›†æ—¥æœŸ**: 2025-12-06
**æ¨¡å‹**: SAC+GeMS trained to 50,000 steps
**ç§å­**: 58407201
**è½¨è¿¹æ•°é‡**: 10,000 per environment
**Episode é•¿åº¦**: 100 steps

## ç¯å¢ƒåˆ—è¡¨

| ç¯å¢ƒ | ç”¨æˆ·ç±»å‹ | ç‚¹å‡»æ¨¡å‹ | å¤šæ ·æ€§æƒ©ç½š | æ•°æ®æ–‡ä»¶ |
|------|---------|---------|-----------|---------|
| diffuse_topdown | Diffuse | tdPBM | 1.0 | diffuse_topdown_medium_10000traj.pkl |
| diffuse_mix | Diffuse | mixPBM | 1.0 | diffuse_mix_medium_10000traj.pkl |
| diffuse_divpen | Diffuse | mixPBM | 3.0 | diffuse_divpen_medium_10000traj.pkl |
| focused_topdown | Focused | tdPBM | 1.0 | focused_topdown_medium_10000traj.pkl |
| focused_mix | Focused | mixPBM | 1.0 | focused_mix_medium_10000traj.pkl |
| focused_divpen | Focused | mixPBM | 3.0 | focused_divpen_medium_10000traj.pkl |

## æ¨¡å‹æ¥æº

æ‰€æœ‰æ•°æ®ä½¿ç”¨ä»¥ä¸‹æ¨¡å‹æ”¶é›†ï¼š
```
checkpoints/online_rl/{env}/SAC+GeMS_Medium_GeMS_{env}_agentseed58407201_gamma0.8_step50000.ckpt
```

## è®­ç»ƒé…ç½®

- lambda_KL: 1.0
- lambda_click: 0.5
- gamma: 0.8
- è®­ç»ƒæ­¥æ•°: 50,000 steps
- éªŒè¯é¢‘ç‡: æ¯ 1000 episodes

## æ•°æ®è´¨é‡æŒ‡æ ‡

[åœ¨æ•°æ®æ”¶é›†å®Œæˆåå¡«å†™]

| ç¯å¢ƒ | Mean Reward | Std Reward | Min Reward | Max Reward |
|------|------------|-----------|-----------|-----------|
| diffuse_topdown | TBD | TBD | TBD | TBD |
| ... | ... | ... | ... | ... |
```

---

## å››ã€åç»­æ­¥éª¤

### 4.1 ä½¿ç”¨ Medium æ•°æ®è®­ç»ƒç¦»çº¿ RL ç®—æ³•

æ•°æ®æ”¶é›†å®Œæˆåï¼Œå¯ä»¥ä½¿ç”¨è¿™äº›æ•°æ®è®­ç»ƒç¦»çº¿ RL ç®—æ³•ï¼ˆå¦‚ CQL, IQL, BCQ ç­‰ï¼‰ã€‚

### 4.2 æ”¶é›† Expert æ•°æ®ï¼ˆå¯é€‰ï¼‰

å¦‚æœéœ€è¦æ›´é«˜è´¨é‡çš„æ•°æ®ï¼Œå¯ä»¥ï¼š
1. ç»§ç»­è®­ç»ƒæ¨¡å‹åˆ° 100,000 æ­¥
2. ä½¿ç”¨ 100k æ­¥çš„æ¨¡å‹æ”¶é›† Expert æ•°æ®
3. é‡å¤æœ¬æ–‡æ¡£çš„æ•°æ®æ”¶é›†æµç¨‹

### 4.3 æ•°æ®æ··åˆå®éªŒï¼ˆå¯é€‰ï¼‰

å¯ä»¥å°è¯•æ··åˆä¸åŒè´¨é‡çš„æ•°æ®ï¼š
- Random + Medium
- Medium + Expert
- Random + Medium + Expert

---

## äº”ã€æ•…éšœæ’æŸ¥

### 5.1 æ¨¡å‹åŠ è½½å¤±è´¥

**é—®é¢˜**: æ•°æ®æ”¶é›†æ—¶æç¤ºæ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶

**è§£å†³**:
```bash
# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls checkpoints/online_rl/*/SAC+GeMS_Medium_*_step50000.ckpt

# å¦‚æœæ–‡ä»¶åä¸åŒ¹é…ï¼Œæ›´æ–°è„šæœ¬ä¸­çš„ MODEL_PATH
```

### 5.2 æ•°æ®æ”¶é›†é€Ÿåº¦æ…¢

**é—®é¢˜**: æ•°æ®æ”¶é›†è¿›åº¦ç¼“æ…¢

**è§£å†³**:
- å‡å°‘ `NUM_TRAJECTORIES`ï¼ˆå¦‚æ”¹ä¸º 5000ï¼‰
- å¢åŠ  GPU æ•°é‡ï¼Œå¹¶è¡Œæ”¶é›†æ›´å¤šç¯å¢ƒ
- æ£€æŸ¥ GPU åˆ©ç”¨ç‡ï¼š`nvidia-smi`

### 5.3 æ•°æ®æ–‡ä»¶æŸå

**é—®é¢˜**: æ•°æ®æ–‡ä»¶æ— æ³•åŠ è½½æˆ–å¤§å°å¼‚å¸¸

**è§£å†³**:
```bash
# åˆ é™¤æŸåçš„æ–‡ä»¶
rm data/offline_datasets/medium/{env}_medium_10000traj.pkl

# é‡æ–°æ”¶é›†è¯¥ç¯å¢ƒçš„æ•°æ®
# ä¿®æ”¹è„šæœ¬åªæ”¶é›†ç‰¹å®šç¯å¢ƒ
```

---

## å…­ã€æ£€æŸ¥æ¸…å•

åœ¨å¼€å§‹ä¸‹ä¸€æ­¥ä¹‹å‰ï¼Œç¡®è®¤ä»¥ä¸‹æ‰€æœ‰é¡¹ç›®ï¼š

### è®­ç»ƒé˜¶æ®µ
- [ ] 6 ä¸ªç¯å¢ƒçš„è®­ç»ƒéƒ½å·²å®Œæˆï¼ˆåˆ°è¾¾ 50,000 æ­¥ï¼‰
- [ ] æ‰€æœ‰ `*_step50000.ckpt` æ–‡ä»¶éƒ½å·²ç”Ÿæˆ
- [ ] SwanLab ä¸Šçš„è®­ç»ƒæ›²çº¿æ­£å¸¸
- [ ] éªŒè¯ reward è¾¾åˆ°åˆç†æ°´å¹³

### æ•°æ®æ”¶é›†é˜¶æ®µ
- [ ] æ•°æ®æ”¶é›†è„šæœ¬å·²åˆ›å»ºå¹¶æµ‹è¯•
- [ ] æ¨¡å‹è·¯å¾„æ­£ç¡®é…ç½®
- [ ] æ•°æ®ä¿å­˜ç›®å½•å·²åˆ›å»º
- [ ] 6 ä¸ªç¯å¢ƒçš„æ•°æ®éƒ½å·²æ”¶é›†å®Œæˆ
- [ ] æ•°æ®æ–‡ä»¶å¤§å°åˆç†ä¸”å®Œæ•´

### æ•°æ®éªŒè¯é˜¶æ®µ
- [ ] æ‰€æœ‰æ•°æ®æ–‡ä»¶éƒ½å¯ä»¥æ­£å¸¸åŠ è½½
- [ ] Reward åˆ†å¸ƒåˆç†ï¼ˆé«˜äº Random æ•°æ®ï¼‰
- [ ] è½¨è¿¹æ•°é‡æ­£ç¡®ï¼ˆ10,000 per environmentï¼‰
- [ ] å…ƒæ•°æ®æ–‡æ¡£å·²åˆ›å»º

---

## ä¸ƒã€å‚è€ƒä¿¡æ¯

### ç›¸å…³æ–‡ä»¶è·¯å¾„

**è®­ç»ƒè„šæœ¬**: `scripts/batch_runs/run_medium_collection_training.sh`
**æ•°æ®æ”¶é›†è„šæœ¬**: `scripts/batch_runs/collect_medium_data.sh` (å¾…åˆ›å»º)
**éªŒè¯è„šæœ¬**: `scripts/verify_medium_data.py` (å¾…åˆ›å»º)
**æ¨¡å‹ç›®å½•**: `checkpoints/online_rl/`
**æ•°æ®ç›®å½•**: `data/offline_datasets/medium/`
**æ—¥å¿—ç›®å½•**: `experiments/logs/`

### SwanLab é¡¹ç›®

**é¡¹ç›®é“¾æ¥**: https://swanlab.cn/@Cliff/GeMS_RL_Training_202512
**å®éªŒæ ‡ç­¾**: `medium_collection`, `50k_steps`, `seed_58407201`

### è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ï¼š
- é¡¹ç›® README
- SwanLab å®éªŒè®°å½•
- è®­ç»ƒæ—¥å¿—æ–‡ä»¶

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-12-06
**ä½œè€…**: Claude Code
