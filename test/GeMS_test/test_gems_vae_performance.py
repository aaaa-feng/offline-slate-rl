"""
GeMS VAE æ€§èƒ½æµ‹è¯•è„šæœ¬

æµ‹è¯•ç›®æ ‡ï¼š
1. é‡æ„è´¨é‡è¯„ä¼°ï¼ˆReconstruction Qualityï¼‰
2. Zero-Action Baseline æµ‹è¯•
3. å¤šæ ·æ€§è¯„ä¼°ï¼ˆDiversity Metricsï¼‰
4. ç«¯åˆ°ç«¯æ€§èƒ½å¯¹æ¯”ï¼ˆE2E Performanceï¼‰

ä½œè€…: Claude Code
æ—¥æœŸ: 2026-01-24
"""

import sys
import os
import logging
import argparse
from pathlib import Path
from typing import Dict, Any, List, Tuple
from collections import defaultdict

import numpy as np
import torch
import torch.nn.functional as F
from tqdm import tqdm

# ============================================================================
# è·¯å¾„è®¾ç½®
# ============================================================================
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT / "src"))
sys.path.insert(0, str(PROJECT_ROOT))

print("=" * 80)
print("=== GeMS VAE æ€§èƒ½æµ‹è¯• ===")
print("=" * 80)
print(f"é¡¹ç›®æ ¹ç›®å½•: {PROJECT_ROOT}")
print("=" * 80)
print()

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from src.common.offline.eval_env import OfflineEvalEnv
from src.rankers.gems.rankers import GeMS
from src.rankers.gems.item_embeddings import ItemEmbeddings

# ============================================================================
# é…ç½®æ—¥å¿—
# ============================================================================
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s: %(message)s',
    handlers=[logging.StreamHandler()]
)

# ============================================================================
# æ¨¡å‹é…ç½®
# ============================================================================
GEMS_MODELS = {
    # æ—§ Benchmark æ¨¡å‹ï¼ˆlambda_click=0.5ï¼‰
    "diffuse_mix_expert": {
        "checkpoint": "GeMS_diffuse_mix_expert_latent32_beta1.0_click0.5_seed58407201.ckpt",
        "env_name": "diffuse_mix",
        "dataset_quality": "expert",
        "lambda_click": 0.5,
        "group": "old_benchmark"
    },
    "diffuse_mix_medium": {
        "checkpoint": "GeMS_diffuse_mix_medium_latent32_beta1.0_click0.5_seed58407201.ckpt",
        "env_name": "diffuse_mix",
        "dataset_quality": "medium",
        "lambda_click": 0.5,
        "group": "old_benchmark"
    },
    "diffuse_topdown_expert": {
        "checkpoint": "GeMS_diffuse_topdown_expert_latent32_beta1.0_click0.5_seed58407201.ckpt",
        "env_name": "diffuse_topdown",
        "dataset_quality": "expert",
        "lambda_click": 0.5,
        "group": "old_benchmark"
    },
    "diffuse_topdown_medium": {
        "checkpoint": "GeMS_diffuse_topdown_medium_latent32_beta1.0_click0.5_seed58407201.ckpt",
        "env_name": "diffuse_topdown",
        "dataset_quality": "medium",
        "lambda_click": 0.5,
        "group": "old_benchmark"
    },
    "diffuse_divpen_expert": {
        "checkpoint": "GeMS_diffuse_divpen_expert_latent32_beta1.0_click0.5_seed58407201.ckpt",
        "env_name": "diffuse_divpen",
        "dataset_quality": "expert",
        "lambda_click": 0.5,
        "group": "old_benchmark"
    },
    "diffuse_divpen_medium": {
        "checkpoint": "GeMS_diffuse_divpen_medium_latent32_beta1.0_click0.5_seed58407201.ckpt",
        "env_name": "diffuse_divpen",
        "dataset_quality": "medium",
        "lambda_click": 0.5,
        "group": "old_benchmark"
    },

    # æ–° Benchmark æ¨¡å‹ï¼ˆlambda_click=1.0ï¼‰
    "mix_divpen_v2_b3": {
        "checkpoint": "GeMS_mix_divpen_v2_b3_latent32_beta1.0_click1.0_seed58407201.ckpt",
        "env_name": "mix_divpen",
        "dataset_quality": "v2_b3",
        "boredom_threshold": 3,
        "lambda_click": 1.0,
        "group": "new_benchmark"
    },
    "mix_divpen_v2_b5": {
        "checkpoint": "GeMS_mix_divpen_v2_b5_latent32_beta1.0_click1.0_seed58407201.ckpt",
        "env_name": "mix_divpen",
        "dataset_quality": "v2_b5",
        "boredom_threshold": 5,
        "lambda_click": 1.0,
        "group": "new_benchmark"
    },
    "topdown_divpen_v2_b3": {
        "checkpoint": "GeMS_topdown_divpen_v2_b3_latent32_beta1.0_click1.0_seed58407201.ckpt",
        "env_name": "topdown_divpen",
        "dataset_quality": "v2_b3",
        "boredom_threshold": 3,
        "lambda_click": 1.0,
        "group": "new_benchmark"
    },
    "topdown_divpen_v2_b5": {
        "checkpoint": "GeMS_topdown_divpen_v2_b5_latent32_beta1.0_click1.0_seed58407201.ckpt",
        "env_name": "topdown_divpen",
        "dataset_quality": "v2_b5",
        "boredom_threshold": 5,
        "lambda_click": 1.0,
        "group": "new_benchmark"
    },

    # Epsilon-Greedy æ¨¡å‹ï¼ˆlambda_click=1.0, ä½¿ç”¨é¢„è®­ç»ƒembeddingsï¼‰
    "mix_divpen_epsilon_greedy": {
        "checkpoint": "GeMS_mix_divpen_epsilon-greedy_latentdim32_beta1.0_lambdaclick1.0_lambdaprior0.0_pretrained_seed58407201.ckpt",
        "env_name": "mix_divpen",
        "dataset_quality": "epsilon-greedy",
        "boredom_threshold": 5,
        "lambda_click": 1.0,
        "group": "epsilon_greedy"
    },
    "topdown_divpen_epsilon_greedy": {
        "checkpoint": "GeMS_topdown_divpen_epsilon-greedy_latentdim32_beta1.0_lambdaclick1.0_lambdaprior0.0_pretrained_seed58407201.ckpt",
        "env_name": "topdown_divpen",
        "dataset_quality": "epsilon-greedy",
        "boredom_threshold": 5,
        "lambda_click": 1.0,
        "group": "epsilon_greedy"
    },

    # MFé¢„è®­ç»ƒæ¨¡å‹ï¼ˆ2026-02-01æ›´æ–°ï¼šä½¿ç”¨æ­£ç¡®çš„seed58407201ï¼‰
    "mix_divpen_v2_b5_mf_fixed": {
        "checkpoint": "GeMS_mix_divpen_v2_b5_mf_fixed_latent32_beta1.0_click1.0_seed58407201.ckpt",
        "env_name": "mix_divpen",
        "dataset_quality": "v2_b5",
        "boredom_threshold": 5,
        "lambda_click": 1.0,
        "group": "mf_pretrained"
    },
    "mix_divpen_v2_b5_scratch": {
        "checkpoint": "GeMS_mix_divpen_v2_b5_scratch_latent32_beta1.0_click1.0_seed58407201.ckpt",
        "env_name": "mix_divpen",
        "dataset_quality": "v2_b5",
        "boredom_threshold": 5,
        "lambda_click": 1.0,
        "group": "mf_pretrained"
    },
    "topdown_divpen_v2_b5_mf_fixed": {
        "checkpoint": "GeMS_topdown_divpen_v2_b5_mf_fixed_latent32_beta1.0_click1.0_seed58407201.ckpt",
        "env_name": "topdown_divpen",
        "dataset_quality": "v2_b5",
        "boredom_threshold": 5,
        "lambda_click": 1.0,
        "group": "mf_pretrained"
    },
    "topdown_divpen_v2_b5_scratch": {
        "checkpoint": "GeMS_topdown_divpen_v2_b5_scratch_latent32_beta1.0_click1.0_seed58407201.ckpt",
        "env_name": "topdown_divpen",
        "dataset_quality": "v2_b5",
        "boredom_threshold": 5,
        "lambda_click": 1.0,
        "group": "mf_pretrained"
    },
}


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================
def load_gems_model(checkpoint_path: str, device: str = "cuda") -> GeMS:
    """åŠ è½½ GeMS æ¨¡å‹"""
    logging.info(f"Loading GeMS model from: {checkpoint_path}")

    # åŠ è½½é¢„è®­ç»ƒçš„ item embeddings
    # æ ¹æ®ç¯å¢ƒåç§°ä½¿ç”¨æ­£ç¡®çš„ embeddings æ–‡ä»¶
    # mix_divpen å’Œ topdown_divpen ä½¿ç”¨ diffuse embeddings
    from rankers.gems.item_embeddings import ItemEmbeddings
    temp_embeddings = ItemEmbeddings.from_pretrained(
        "/data/liyuefeng/offline-slate-rl/data/embeddings/item_embeddings_diffuse.pt",
        device
    )

    # ä½¿ç”¨ GeMS æ ‡å‡†åŠ è½½æ–¹æ³•ï¼ˆä¸ TD3+BC è®­ç»ƒè„šæœ¬ä¸€è‡´ï¼‰
    ranker = GeMS.load_from_checkpoint(
        checkpoint_path,
        map_location=device,
        item_embeddings=temp_embeddings,
        device=device,
        rec_size=10,
        item_embedd_dim=20,  # ä¿®æ­£ï¼šå®é™…embeddingsç»´åº¦ä¸º20
        num_items=1000,
        latent_dim=32,
        lambda_click=1.0,
        lambda_KL=1.0,
        lambda_prior=1.0,
        ranker_lr=3e-3,
        fixed_embedds="scratch",
        ranker_sample=False,
        hidden_layers_infer=[512, 256],
        hidden_layers_decoder=[256, 512]
    )
    ranker.to(device)
    ranker.eval()

    logging.info("âœ“ GeMS model loaded successfully")
    return ranker


def calculate_gini_coefficient(frequencies: np.ndarray) -> float:
    """è®¡ç®—åŸºå°¼ç³»æ•°"""
    sorted_freq = np.sort(frequencies)
    n = len(frequencies)
    index = np.arange(1, n + 1)
    return (2 * np.sum(index * sorted_freq)) / (n * np.sum(sorted_freq)) - (n + 1) / n


def calculate_diversity_metrics(slates: np.ndarray, num_items: int = 1000) -> Dict[str, float]:
    """
    è®¡ç®—å¤šæ ·æ€§æŒ‡æ ‡
    
    Args:
        slates: [num_slates, slate_size] çš„ Slate æ•°ç»„
        num_items: ç‰©å“æ€»æ•°
        
    Returns:
        diversity_metrics: åŒ…å«å„ç§å¤šæ ·æ€§æŒ‡æ ‡çš„å­—å…¸
    """
    num_slates, slate_size = slates.shape
    
    # 1. ç‰©å“è¦†ç›–ç‡
    unique_items = np.unique(slates)
    item_coverage = len(unique_items) / num_items
    
    # 2. è¿ç»­ Slate é‡å ç‡
    overlaps = []
    for i in range(num_slates - 1):
        slate1 = set(slates[i])
        slate2 = set(slates[i + 1])
        overlap = len(slate1 & slate2) / slate_size
        overlaps.append(overlap)
    consecutive_overlap = np.mean(overlaps) if overlaps else 0.0
    
    # 3. ç‰©å“æµè¡Œåº¦åˆ†å¸ƒï¼ˆåŸºå°¼ç³»æ•°ï¼‰
    item_counts = np.bincount(slates.flatten(), minlength=num_items)
    gini = calculate_gini_coefficient(item_counts)
    
    # 4. Top-10 ç‰©å“è¦†ç›–ç‡
    top10_items = np.argsort(item_counts)[-10:]
    top10_count = item_counts[top10_items].sum()
    top10_coverage = top10_count / slates.size
    
    return {
        "item_coverage": item_coverage,
        "consecutive_overlap": consecutive_overlap,
        "gini_coefficient": gini,
        "top10_coverage": top10_coverage
    }


class BaselineAgent:
    """
    Baseline Agent for testing GeMS performance.

    ğŸ”¥ REFACTORED: Now outputs slates directly (not latent actions).
    Agents must handle slate decoding internally to match the new architecture.
    """
    def __init__(self, strategy: str = "zero", mean_action: np.ndarray = None, action_dim: int = 32, ranker = None):
        """
        Initialize Baseline Agent.

        Args:
            strategy: "zero", "random", or "mean"
            mean_action: Mean latent action (for "mean" strategy)
            action_dim: Latent action dimension
            ranker: GeMS ranker for decoding latent actions to slates
        """
        self.strategy = strategy
        self.mean_action = mean_action
        self.action_dim = action_dim
        self.ranker = ranker

        if self.ranker is None:
            raise ValueError("BaselineAgent requires a ranker for slate decoding.")

    def act(self, obs: Dict[str, Any], deterministic: bool = True) -> np.ndarray:
        """
        Generate baseline latent action and decode to slate.

        Returns:
            slate: numpy array of shape [rec_size]
        """
        # Generate latent action based on strategy
        if self.strategy == "zero":
            latent_action = np.zeros(self.action_dim, dtype=np.float32)
        elif self.strategy == "random":
            latent_action = np.random.randn(self.action_dim).astype(np.float32)
        elif self.strategy == "mean":
            latent_action = self.mean_action.copy()
        else:
            raise ValueError(f"Unknown strategy: {self.strategy}")

        # ğŸ”¥ NEW: Decode to slate using ranker
        latent_action_tensor = torch.FloatTensor(latent_action).unsqueeze(0).to(self.ranker.device)
        slate_tensor = self.ranker.rank(latent_action_tensor).squeeze(0)
        slate = slate_tensor.cpu().numpy()

        return slate

    def reset_hidden(self):
        pass


# ============================================================================
# æµ‹è¯•å‡½æ•°ï¼šBaseline ç­–ç•¥æµ‹è¯•ï¼ˆZero/Random/Mean-Actionï¼‰
# ============================================================================
def test_zero_action_baseline(models_to_test: List[str], args):
    """æµ‹è¯•ä¸‰ç§ Baseline ç­–ç•¥æ€§èƒ½ï¼šZero-Action, Random-Action, Mean-Action"""

    print("\n" + "=" * 80)
    print("=== æµ‹è¯• 1: Baseline ç­–ç•¥æ€§èƒ½ï¼ˆZero/Random/Mean-Actionï¼‰ ===")
    print("=" * 80)
    print()

    # å­˜å‚¨æ‰€æœ‰ç»“æœï¼š{model_name: {strategy: {mean_reward, std_reward}}}
    all_results = {}

    # å®šä¹‰ä¸‰ç§æµ‹è¯•ç­–ç•¥
    strategies = ["zero", "random", "mean"]
    strategy_names = {
        "zero": "Zero-Action",
        "random": "Random-Action",
        "mean": "Mean-Action"
    }

    for model_name in models_to_test:
        model_config = GEMS_MODELS[model_name]
        all_results[model_name] = {"group": model_config["group"]}

        print(f"\n{'='*80}")
        print(f"æµ‹è¯•æ¨¡å‹: {model_name}")
        print(f"{'='*80}")

        # ğŸ”¥ åŠ è½½æŒ‡å®šçš„ GeMS checkpoint
        checkpoint_path = PROJECT_ROOT / "checkpoints/gems/offline" / model_config["checkpoint"]
        print(f"ğŸ“¦ GeMS Checkpoint: {checkpoint_path}")
        print(f"   Group: {model_config['group']}")
        print(f"   Lambda_click: {model_config['lambda_click']}")

        try:
            ranker = load_gems_model(str(checkpoint_path), args.device)
        except Exception as e:
            print(f"\nâœ— åŠ è½½ GeMS æ¨¡å‹å¤±è´¥: {e}")
            continue

        # åˆå§‹åŒ–è¯„ä¼°ç¯å¢ƒï¼ˆä¸å†ä¼ å…¥rankerï¼Œagentsç°åœ¨å†…éƒ¨å¤„ç†slateè§£ç ï¼‰
        env_params = {
            "env_name": model_config["env_name"],
            "device": args.device,
            "seed": args.seed,
            "verbose": False
        }

        # æ·»åŠ ç‰¹å®šå‚æ•°
        if "dataset_quality" in model_config:
            env_params["dataset_quality"] = model_config["dataset_quality"]
        if "boredom_threshold" in model_config:
            env_params["env_param_override"] = {
                "boredom_threshold": model_config["boredom_threshold"]
            }

        try:
            eval_env = OfflineEvalEnv(**env_params)

            # æµ‹è¯•ä¸‰ç§ç­–ç•¥
            for strategy in strategies:
                print(f"\n  [{strategy_names[strategy]}]", end=" ")

                # åˆ›å»ºå¯¹åº”çš„ agent
                if strategy == "mean":
                    # Mean-Action éœ€è¦è®¡ç®—æ•°æ®é›†çš„å¹³å‡åŠ¨ä½œ
                    # è¿™é‡Œä½¿ç”¨é›¶å‘é‡ä½œä¸ºè¿‘ä¼¼ï¼ˆå› ä¸º VAE æ½œç©ºé—´é€šå¸¸ä»¥0ä¸ºä¸­å¿ƒï¼‰
                    mean_action = np.zeros(32, dtype=np.float32)
                    agent = BaselineAgent(strategy="mean", mean_action=mean_action, action_dim=32, ranker=ranker)
                else:
                    agent = BaselineAgent(strategy=strategy, action_dim=32, ranker=ranker)

                # è¯„ä¼°
                metrics = eval_env.evaluate_policy(
                    agent=agent,
                    num_episodes=args.num_episodes,
                    deterministic=True
                )

                all_results[model_name][strategy] = {
                    "mean_reward": metrics['mean_reward'],
                    "std_reward": metrics['std_reward']
                }

                print(f"âœ“ {metrics['mean_reward']:.2f} Â± {metrics['std_reward']:.2f}")

        except Exception as e:
            print(f"\nâœ— æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
            for strategy in strategies:
                all_results[model_name][strategy] = {
                    "mean_reward": 0.0,
                    "std_reward": 0.0
                }
            continue

    # æ‰“å°æ±‡æ€»è¡¨æ ¼
    print("\n" + "=" * 80)
    print("=== Baseline ç­–ç•¥ç»“æœæ±‡æ€» ===")
    print("=" * 80)
    print(f"{'æ¨¡å‹':<35} {'åˆ†ç»„':<15} {'Zero-Action':<18} {'Random-Action':<18} {'Mean-Action':<18}")
    print("-" * 80)

    for model_name, results in all_results.items():
        if "zero" in results:  # ç¡®ä¿æµ‹è¯•æˆåŠŸ
            zero_str = f"{results['zero']['mean_reward']:.2f}Â±{results['zero']['std_reward']:.2f}"
            random_str = f"{results['random']['mean_reward']:.2f}Â±{results['random']['std_reward']:.2f}"
            mean_str = f"{results['mean']['mean_reward']:.2f}Â±{results['mean']['std_reward']:.2f}"
            print(f"{model_name:<35} {results['group']:<15} {zero_str:<18} {random_str:<18} {mean_str:<18}")

    print("=" * 80)


# ============================================================================
# æµ‹è¯•å‡½æ•°ï¼šå¤šæ ·æ€§è¯„ä¼°
# ============================================================================
def test_diversity_metrics(models_to_test: List[str], args):
    """æµ‹è¯•å¤šæ ·æ€§æŒ‡æ ‡"""
    
    print("\n" + "=" * 80)
    print("=== æµ‹è¯• 2: å¤šæ ·æ€§è¯„ä¼° ===")
    print("=" * 80)
    print("âš ï¸  æ­¤åŠŸèƒ½éœ€è¦å®ç° GeMS æ¨¡å‹çš„ Slate ç”Ÿæˆæ¥å£")
    print("=" * 80)
    # TODO: å®ç°å¤šæ ·æ€§æµ‹è¯•


# ============================================================================
# æµ‹è¯•å‡½æ•°ï¼šé‡æ„è´¨é‡è¯„ä¼°
# ============================================================================
def test_reconstruction_quality(models_to_test: List[str], args):
    """æµ‹è¯•é‡æ„è´¨é‡"""
    
    print("\n" + "=" * 80)
    print("=== æµ‹è¯• 3: é‡æ„è´¨é‡è¯„ä¼° ===")
    print("=" * 80)
    print("âš ï¸  æ­¤åŠŸèƒ½éœ€è¦å®ç° GeMS æ¨¡å‹çš„é‡æ„è¯„ä¼°æ¥å£")
    print("=" * 80)
    # TODO: å®ç°é‡æ„è´¨é‡æµ‹è¯•



# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================
def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="GeMS VAE æ€§èƒ½æµ‹è¯•")
    parser.add_argument(
        "--test_mode",
        type=str,
        default="zero_action",
        choices=["zero_action", "diversity", "reconstruction", "all"],
        help="æµ‹è¯•æ¨¡å¼"
    )
    parser.add_argument(
        "--models",
        type=str,
        nargs="+",
        default=None,
        help="è¦æµ‹è¯•çš„æ¨¡å‹åç§°åˆ—è¡¨ï¼ˆé»˜è®¤æµ‹è¯•æ‰€æœ‰æ¨¡å‹ï¼‰"
    )
    parser.add_argument(
        "--num_episodes",
        type=int,
        default=100,
        help="Zero-Action æµ‹è¯•çš„ Episode æ•°é‡"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cuda" if torch.cuda.is_available() else "cpu",
        help="è®¾å¤‡"
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=58407201,
        help="éšæœºç§å­"
    )
    
    args = parser.parse_args()
    
    print("\n" + "=" * 80)
    print("=== æµ‹è¯•é…ç½® ===")
    print("=" * 80)
    print(f"æµ‹è¯•æ¨¡å¼: {args.test_mode}")
    print(f"è®¾å¤‡: {args.device}")
    print(f"éšæœºç§å­: {args.seed}")
    print("=" * 80)
    print()
    
    # ç¡®å®šè¦æµ‹è¯•çš„æ¨¡å‹
    if args.models is None:
        models_to_test = list(GEMS_MODELS.keys())
    else:
        models_to_test = args.models
    
    print(f"å°†æµ‹è¯• {len(models_to_test)} ä¸ªæ¨¡å‹:")
    for model_name in models_to_test:
        print(f"  - {model_name}")
    print()
    
    # æ ¹æ®æµ‹è¯•æ¨¡å¼æ‰§è¡Œç›¸åº”çš„æµ‹è¯•
    if args.test_mode == "zero_action":
        test_zero_action_baseline(models_to_test, args)
    elif args.test_mode == "diversity":
        test_diversity_metrics(models_to_test, args)
    elif args.test_mode == "reconstruction":
        test_reconstruction_quality(models_to_test, args)
    elif args.test_mode == "all":
        test_zero_action_baseline(models_to_test, args)
        test_diversity_metrics(models_to_test, args)
        test_reconstruction_quality(models_to_test, args)
    
    print("\n" + "=" * 80)
    print("=== æµ‹è¯•å®Œæˆ ===")
    print("=" * 80)


if __name__ == "__main__":
    main()

