# ä»£ç ä¿®å¤æ¸…å•

**æ—¥æœŸ**: 2025-12-01
**çŠ¶æ€**: gems_env.pyå·²ä¿®å¤ï¼ŒCQL/IQLå¾…ä¿®å¤

---

## âœ… å·²å®Œæˆçš„ä¿®å¤

### 1. gems_env.py - ç¯å¢ƒåŒ…è£…å™¨

**ä¿®å¤å†…å®¹**:
- âœ… æ­£ç¡®åŠ è½½belief_encoderï¼ˆä½¿ç”¨ModelLoaderï¼‰
- âœ… æ­£ç¡®åŠ è½½GeMS rankerï¼ˆä½¿ç”¨ModelLoaderï¼‰
- âœ… å®ç°`reset()`æ–¹æ³•ï¼Œæ­£ç¡®åˆå§‹åŒ–belief state
- âœ… å®ç°`step()`æ–¹æ³•ï¼Œæ­£ç¡®æ›´æ–°belief state
- âœ… å®ç°`_decode_action()`æ–¹æ³•ï¼Œä½¿ç”¨rankerå°†latent actionè§£ç ä¸ºslate
- âœ… æ·»åŠ æ¸…æ™°çš„è­¦å‘Šä¿¡æ¯ï¼Œè¯´æ˜åœ¨çº¿è¯„ä¼°çš„é™åˆ¶

**å…³é”®æ”¹è¿›**:
```python
# åŠ è½½belief encoderå’Œranker
self.model_loader = ModelLoader()
self.belief_encoder = self.model_loader.load_belief_encoder(env_name)
self.ranker = self.model_loader.load_ranker(env_name, ranker_type="GeMS")

# resetæ—¶åˆå§‹åŒ–belief state
self.belief_state = self.belief_encoder.forward(self.current_obs)

# stepæ—¶æ›´æ–°belief state
self.belief_state = self.belief_encoder.forward(next_obs, done=done)

# è§£ç latent action
slate = self.ranker.rank(latent_tensor)
```

---

## ğŸ”´ å¾…ä¿®å¤ï¼šCQLç®—æ³•æ–‡ä»¶

**æ–‡ä»¶**: `offline_rl_baselines/algorithms/cql.py`

### é—®é¢˜1: å†—ä½™çš„ReplayBufferå®šä¹‰

**ä½ç½®**: Line 123-182
**é—®é¢˜**: æ–‡ä»¶å†…éƒ¨é‡æ–°å®šä¹‰äº†ReplayBufferç±»ï¼Œä¸`common/buffer.py`å†²çª
**ä¿®å¤**: åˆ é™¤æ•´ä¸ªReplayBufferç±»å®šä¹‰ï¼ˆLine 123-182ï¼‰

### é—®é¢˜2: å†—ä½™çš„å·¥å…·å‡½æ•°

**ä½ç½®**:
- Line 86-90: `soft_update()` - å·²åœ¨`common/utils.py`ä¸­å®šä¹‰
- Line 91-95: `compute_mean_std()` - å·²åœ¨`common/utils.py`ä¸­å®šä¹‰
- Line 97-99: `normalize_states()` - å¯ä»¥åˆ é™¤æˆ–ç§»åˆ°common
- Line 185-196: `set_seed()` - å·²åœ¨`common/utils.py`ä¸­å®šä¹‰

**ä¿®å¤**: åˆ é™¤è¿™äº›å‡½æ•°ï¼Œä½¿ç”¨commonä¸­çš„ç‰ˆæœ¬

### é—®é¢˜3: d4rlä¾èµ–

**ä½ç½®**: Line 849
```python
dataset = d4rl.qlearning_dataset(env)
```

**ä¿®å¤**: æ”¹ä¸ºåŠ è½½æœ¬åœ°.npzæ–‡ä»¶
```python
dataset = np.load(config.dataset_path)
```

### é—®é¢˜4: pyrallisä¾èµ–

**ä½ç½®**: Line 842
```python
@pyrallis.wrap()
def train(config: TrainConfig):
```

**ä¿®å¤**:
1. åˆ é™¤`@pyrallis.wrap()`è£…é¥°å™¨
2. å°†`TrainConfig`æ”¹ä¸ºdataclassï¼ˆä¿æŒä¸å˜ï¼‰
3. åˆ›å»ºç‹¬ç«‹çš„è®­ç»ƒè„šæœ¬`scripts/train_cql.py`ä½¿ç”¨argparse

### é—®é¢˜5: è®­ç»ƒå‡½æ•°ä¸­çš„d4rlè¯„ä¼°

**ä½ç½®**: Line 987
```python
{"d4rl_normalized_score": normalized_eval_score}
```

**é—®é¢˜**: ä½¿ç”¨äº†d4rlçš„å½’ä¸€åŒ–è¯„åˆ†
**ä¿®å¤**:
- é€‰é¡¹1: åˆ é™¤d4rlå½’ä¸€åŒ–è¯„åˆ†
- é€‰é¡¹2: ä½¿ç”¨è‡ªå®šä¹‰çš„å½’ä¸€åŒ–æ–¹æ³•

### é—®é¢˜6: é»˜è®¤é…ç½®ä¸é€‚ç”¨

**ä½ç½®**: Line 31-85 (TrainConfig)
```python
env: str = "halfcheetah-medium-expert-v2"  # MuJoCoç¯å¢ƒ
```

**ä¿®å¤**: æ”¹ä¸ºGeMSç¯å¢ƒ
```python
env_name: str = "diffuse_topdown"
state_dim: int = 20
action_dim: int = 32
```

---

## ğŸ”´ å¾…ä¿®å¤ï¼šIQLç®—æ³•æ–‡ä»¶

**æ–‡ä»¶**: `offline_rl_baselines/algorithms/iql.py`

### ç›¸åŒçš„é—®é¢˜

IQLæ–‡ä»¶å­˜åœ¨ä¸CQLç›¸åŒçš„é—®é¢˜ï¼š
1. âœ… å†—ä½™çš„ReplayBufferå®šä¹‰
2. âœ… å†—ä½™çš„å·¥å…·å‡½æ•°
3. âœ… d4rlä¾èµ–ï¼ˆLine 285ï¼‰
4. âœ… pyrallisä¾èµ–ï¼ˆLine 256ï¼‰
5. âœ… é»˜è®¤é…ç½®ä¸é€‚ç”¨

---

## ğŸ“ å»ºè®®çš„ä¿®å¤æ–¹æ¡ˆ

### æ–¹æ¡ˆA: å®Œæ•´é‡æ„ï¼ˆæ¨èï¼Œä½†è€—æ—¶ï¼‰

1. **æ¸…ç†CQL/IQLæ–‡ä»¶**:
   - åˆ é™¤æ‰€æœ‰å†—ä½™ä»£ç 
   - åªä¿ç•™æ ¸å¿ƒç®—æ³•ç±»ï¼ˆContinuousCQL, IQLï¼‰
   - ç§»é™¤d4rlå’Œpyrallisä¾èµ–

2. **åˆ›å»ºè®­ç»ƒè„šæœ¬**:
   - `scripts/train_cql.py` - å‚è€ƒ`train_td3_bc.py`
   - `scripts/train_iql.py` - å‚è€ƒ`train_td3_bc.py`

3. **æ·»åŠ è®­ç»ƒå‡½æ•°**:
   - åœ¨`algorithms/cql.py`æœ«å°¾æ·»åŠ `train_cql(config)`å‡½æ•°
   - åœ¨`algorithms/iql.py`æœ«å°¾æ·»åŠ `train_iql(config)`å‡½æ•°

### æ–¹æ¡ˆB: æœ€å°ä¿®æ”¹ï¼ˆå¿«é€Ÿï¼Œä½†ä¸å½»åº•ï¼‰

1. **åªä¿®å¤å…³é”®é—®é¢˜**:
   - ä¿®æ”¹Line 849: æ”¹ä¸ºåŠ è½½æœ¬åœ°æ•°æ®
   - ä¿®æ”¹Line 871-877: ä½¿ç”¨GemsReplayBuffer
   - åˆ é™¤`@pyrallis.wrap()`è£…é¥°å™¨

2. **åˆ›å»ºç®€å•çš„è®­ç»ƒè„šæœ¬**:
   - ç›´æ¥è°ƒç”¨ä¿®æ”¹åçš„`train()`å‡½æ•°
   - ä½¿ç”¨argparseè§£æå‚æ•°å¹¶æ„é€ TrainConfig

### æ–¹æ¡ˆC: å…ˆéªŒè¯TD3+BCï¼Œå†å†³å®šï¼ˆæœ€åŠ¡å®ï¼‰

1. **ç«‹å³æµ‹è¯•TD3+BC**:
   ```bash
   python offline_rl_baselines/scripts/train_td3_bc.py \
       --env_name diffuse_topdown \
       --seed 0 \
       --max_timesteps 10000 \  # å…ˆè·‘10K stepsæµ‹è¯•
       --device cuda
   ```

2. **å¦‚æœTD3+BCå·¥ä½œæ­£å¸¸**:
   - å†èŠ±æ—¶é—´ä¿®å¤CQL/IQL
   - å› ä¸ºè‡³å°‘æœ‰ä¸€ä¸ªbaselineå¯ç”¨

3. **å¦‚æœTD3+BCæœ‰é—®é¢˜**:
   - å…ˆè§£å†³TD3+BCçš„é—®é¢˜
   - å†è€ƒè™‘CQL/IQL

---

## ğŸ¯ å…³é”®ç†è§£ï¼šæ½œç©ºé—´è®­ç»ƒ

### æ•°æ®æµç¨‹

```
æ•°æ®æ”¶é›†é˜¶æ®µ:
RecSim obs â†’ belief_encoder â†’ belief_state (20ç»´)
                                    â†“
                            SAC agent â†’ latent_action (32ç»´)
                                    â†“
                            GeMS ranker â†’ slate (10ä¸ªç‰©å“)
                                    â†“
                            environment â†’ reward

ä¿å­˜åˆ°æ•°æ®é›†:
- observations: belief_state (20ç»´)
- actions: latent_action (32ç»´)
- rewards, next_observations, terminals
```

```
ç¦»çº¿RLè®­ç»ƒé˜¶æ®µ:
åŠ è½½æ•°æ®é›† â†’ (belief_state, latent_action, reward)
                    â†“
        åœ¨æ½œç©ºé—´ä¸­è®­ç»ƒç­–ç•¥: belief_state â†’ latent_action
                    â†“
        ä¸éœ€è¦rankerï¼è®­ç»ƒå®Œå…¨åœ¨æ½œç©ºé—´è¿›è¡Œ
```

```
åœ¨çº¿è¯„ä¼°é˜¶æ®µï¼ˆå¯é€‰ï¼‰:
RecSim obs â†’ belief_encoder â†’ belief_state (20ç»´)
                                    â†“
                    è®­ç»ƒå¥½çš„ç­–ç•¥ â†’ latent_action (32ç»´)
                                    â†“
                    GeMS ranker â†’ slate (10ä¸ªç‰©å“)
                                    â†“
                    environment â†’ reward
```

### å…³é”®ç‚¹

1. **è®­ç»ƒä¸éœ€è¦ranker**:
   - ç¦»çº¿RLç®—æ³•åœ¨æ½œç©ºé—´ä¸­è®­ç»ƒ
   - è¾“å…¥: belief_state (20ç»´)
   - è¾“å‡º: latent_action (32ç»´)
   - å®Œå…¨ä¸æ¶‰åŠslate

2. **è¯„ä¼°éœ€è¦ranker**:
   - å¦‚æœè¦åœ¨çœŸå®ç¯å¢ƒä¸­è¯„ä¼°
   - éœ€è¦å°†latent_actionè§£ç ä¸ºslate
   - è¿™æ—¶æ‰éœ€è¦ranker

3. **å½“å‰çŠ¶æ€**:
   - âœ… æ•°æ®å·²æ”¶é›†ï¼ˆåŒ…å«belief_stateå’Œlatent_actionï¼‰
   - âœ… TD3+BCå¯ä»¥åœ¨æ½œç©ºé—´ä¸­è®­ç»ƒ
   - âœ… gems_env.pyå·²ä¿®å¤ï¼Œæ”¯æŒåœ¨çº¿è¯„ä¼°ï¼ˆå¦‚æœéœ€è¦ï¼‰
   - âš ï¸ CQL/IQLéœ€è¦ä¿®å¤æ‰èƒ½è®­ç»ƒ

---

## ğŸ“Š æµ‹è¯•è®¡åˆ’

### é˜¶æ®µ1: éªŒè¯TD3+BCï¼ˆç«‹å³æ‰§è¡Œï¼‰

```bash
# æµ‹è¯•æ•°æ®åŠ è½½
python -c "
import numpy as np
data = np.load('offline_datasets/diffuse_topdown_expert.npz')
print('Data loaded successfully')
print('Observations:', data['observations'].shape)
print('Actions:', data['actions'].shape)
"

# æµ‹è¯•çŸ­æ—¶é—´è®­ç»ƒï¼ˆ10K stepsï¼Œçº¦5-10åˆ†é’Ÿï¼‰
python offline_rl_baselines/scripts/train_td3_bc.py \
    --env_name diffuse_topdown \
    --seed 0 \
    --max_timesteps 10000 \
    --batch_size 256 \
    --device cuda \
    --no_normalize  # å…ˆä¸å½’ä¸€åŒ–ï¼Œæµ‹è¯•åŸºæœ¬æµç¨‹

# æ£€æŸ¥æ—¥å¿—
tail -f offline_rl_baselines/experiments/logs/td3_bc_*.log
```

### é˜¶æ®µ2: ä¿®å¤CQL/IQLï¼ˆå¦‚æœTD3+BCæˆåŠŸï¼‰

æ ¹æ®æ–¹æ¡ˆAæˆ–æ–¹æ¡ˆBè¿›è¡Œä¿®å¤

### é˜¶æ®µ3: å®Œæ•´è®­ç»ƒï¼ˆå¦‚æœæµ‹è¯•æˆåŠŸï¼‰

```bash
# è¿è¡Œå®Œæ•´çš„TD3+BCè®­ç»ƒï¼ˆ1M stepsï¼‰
bash offline_rl_baselines/scripts/run_all_baselines.sh td3_bc
```

---

## ğŸ’¡ å»ºè®®

1. **ä¼˜å…ˆçº§**:
   - ğŸ”¥ **æœ€é«˜**: æµ‹è¯•TD3+BCæ˜¯å¦èƒ½æ­£å¸¸è®­ç»ƒ
   - ğŸ”¥ **é«˜**: ä¿®å¤CQL/IQLçš„å…³é”®é—®é¢˜ï¼ˆd4rlä¾èµ–ï¼‰
   - ğŸ“ **ä¸­**: æ¸…ç†å†—ä½™ä»£ç 
   - ğŸ“ **ä½**: å®Œå–„åœ¨çº¿è¯„ä¼°åŠŸèƒ½

2. **æ—¶é—´åˆ†é…**:
   - TD3+BCæµ‹è¯•: 10-30åˆ†é’Ÿ
   - CQL/IQLæœ€å°ä¿®å¤: 1-2å°æ—¶
   - CQL/IQLå®Œæ•´é‡æ„: 4-6å°æ—¶

3. **é£é™©æ§åˆ¶**:
   - å…ˆç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªç®—æ³•ï¼ˆTD3+BCï¼‰å¯ç”¨
   - å†é€æ­¥æ·»åŠ å…¶ä»–ç®—æ³•
   - é¿å…åŒæ—¶ä¿®æ”¹å¤šä¸ªæ–‡ä»¶å¯¼è‡´éš¾ä»¥è°ƒè¯•

---

**ä¸‹ä¸€æ­¥è¡ŒåŠ¨**: è¯·å†³å®šé‡‡ç”¨å“ªä¸ªæ–¹æ¡ˆï¼Œæˆ–è€…å…ˆæµ‹è¯•TD3+BC
