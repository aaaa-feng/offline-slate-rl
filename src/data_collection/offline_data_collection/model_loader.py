#!/usr/bin/env python3
"""
æ¨¡å‹åŠ è½½å™¨
ç”¨äºåŠ è½½è®­ç»ƒå¥½çš„GeMSæ¨¡å‹è¿›è¡Œæ•°æ®æ”¶é›†
"""
import torch
import sys
import os
from pathlib import Path
from typing import Dict, Any, Optional, Tuple

# æ·»åŠ GeMSè·¯å¾„ - åŠ¨æ€è·å–é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.append(str(PROJECT_ROOT))

from modules.agents import SAC, SlateQ, REINFORCE, WolpertingerSAC
from modules.belief_encoders import GRUBelief
from GeMS.modules.rankers import GeMS, TopKRanker, kHeadArgmaxRanker
from GeMS.modules.item_embeddings import ItemEmbeddings, MFEmbeddings
from modules.argument_parser import MyParser

class ModelLoader:
    """æ¨¡å‹åŠ è½½å™¨"""
    
    def __init__(self, models_dir: str = None):
        # åŠ¨æ€è®¾ç½®é»˜è®¤æ¨¡å‹ç›®å½•
        if models_dir is None:
            project_root = Path(__file__).resolve().parent.parent
            models_dir = str(project_root / "offline_data_collection" / "best_models_for_data_collection")
        self.models_dir = models_dir
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # ç¯å¢ƒé…ç½®
        self.env_configs = {
            'diffuse_topdown': {
                'num_items': 1000,
                'rec_size': 10,
                'num_topics': 10,
                'topic_size': 2,
                'item_embedd_dim': 20,
                'belief_state_dim': 20,
                'env_embedds': 'item_embeddings_diffuse.pt'
            },
            'diffuse_mix': {
                'num_items': 1000,
                'rec_size': 10,
                'num_topics': 10,
                'topic_size': 2,
                'item_embedd_dim': 20,
                'belief_state_dim': 20,
                'env_embedds': 'item_embeddings_diffuse.pt'
            },
            'diffuse_divpen': {
                'num_items': 1000,
                'rec_size': 10,
                'num_topics': 10,
                'topic_size': 2,
                'item_embedd_dim': 20,
                'belief_state_dim': 20,
                'env_embedds': 'item_embeddings_diffuse.pt'
            },
            'focused_topdown': {
                'num_items': 1000,
                'rec_size': 10,
                'num_topics': 10,
                'topic_size': 2,
                'item_embedd_dim': 20,
                'belief_state_dim': 20,
                'env_embedds': 'item_embeddings_focused.pt'
            },
            'focused_mix': {
                'num_items': 1000,
                'rec_size': 10,
                'num_topics': 10,
                'topic_size': 2,
                'item_embedd_dim': 20,
                'belief_state_dim': 20,
                'env_embedds': 'item_embeddings_focused.pt'
            },
            'focused_divpen': {
                'num_items': 1000,
                'rec_size': 10,
                'num_topics': 10,
                'topic_size': 2,
                'item_embedd_dim': 20,
                'belief_state_dim': 20,
                'env_embedds': 'item_embeddings_focused.pt'
            }
        }
    
    def load_item_embeddings(self, env_name: str, embedding_type: str = "ideal") -> ItemEmbeddings:
        """
        åŠ è½½ç‰©å“embeddings
        
        Args:
            env_name: ç¯å¢ƒåç§°
            embedding_type: embeddingç±»å‹ (ideal, scratch, mf)
            
        Returns:
            item_embeddings: ItemEmbeddingså¯¹è±¡
        """
        config = self.env_configs[env_name]
        
        if embedding_type == "ideal":
            # åŠ è½½é¢„è®­ç»ƒçš„ideal embeddings
            project_root = Path(__file__).resolve().parent.parent
            embeddings_path = project_root / "data" / "RecSim" / "embeddings" / config['env_embedds']
            embeddings_path = str(embeddings_path)
            if os.path.exists(embeddings_path):
                embeddings_tensor = torch.load(embeddings_path, map_location=self.device)
                item_embeddings = ItemEmbeddings(
                    num_items=config['num_items'],
                    item_embedd_dim=config['item_embedd_dim'],
                    device=self.device
                )
                item_embeddings.embedd.weight.data = embeddings_tensor
                print(f"âœ… æˆåŠŸåŠ è½½ideal embeddings: {embeddings_path}")
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°ideal embeddingsæ–‡ä»¶ {embeddings_path}, ä½¿ç”¨éšæœºåˆå§‹åŒ–")
                item_embeddings = ItemEmbeddings(
                    num_items=config['num_items'],
                    item_embedd_dim=config['item_embedd_dim'],
                    device=self.device
                )
        
        elif embedding_type == "scratch":
            # éšæœºåˆå§‹åŒ–
            item_embeddings = ItemEmbeddings(
                num_items=config['num_items'],
                item_embedd_dim=config['item_embedd_dim'],
                device=self.device
            )
        
        elif embedding_type == "mf":
            # åŠ è½½MF embeddings
            project_root = Path(__file__).resolve().parent.parent
            mf_path = project_root / "data" / "MF_embeddings" / f"{env_name}_moving_env.pt"
            mf_path = str(mf_path)
            if os.path.exists(mf_path):
                item_embeddings = MFEmbeddings(
                    num_items=config['num_items'],
                    item_embedd_dim=config['item_embedd_dim'],
                    device=self.device
                )
                # åŠ è½½MFæƒé‡
                mf_checkpoint = torch.load(mf_path, map_location=self.device)
                item_embeddings.load_state_dict(mf_checkpoint)
            else:
                print(f"è­¦å‘Š: æœªæ‰¾åˆ°MF embeddingsæ–‡ä»¶ {mf_path}, ä½¿ç”¨éšæœºåˆå§‹åŒ–")
                item_embeddings = ItemEmbeddings(
                    num_items=config['num_items'],
                    item_embedd_dim=config['item_embedd_dim'],
                    device=self.device
                )
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„embeddingç±»å‹: {embedding_type}")
        
        return item_embeddings
    
    def load_belief_encoder(self, env_name: str) -> GRUBelief:
        """
        åŠ è½½ä¿¡å¿µç¼–ç å™¨
        
        Args:
            env_name: ç¯å¢ƒåç§°
            
        Returns:
            belief_encoder: GRUBeliefå¯¹è±¡
        """
        config = self.env_configs[env_name]
        
        # åˆ›å»ºitem embeddings (ç”¨äºbelief encoder)
        item_embeddings = self.load_item_embeddings(env_name, "scratch")
        
        # è®¡ç®—input_dim: rec_size * (item_embedd_dim + 1)
        input_dim = config['rec_size'] * (config['item_embedd_dim'] + 1)
        
        belief_encoder = GRUBelief(
            hidden_dim=config['belief_state_dim'],
            input_dim=input_dim,
            item_embeddings=item_embeddings,
            belief_state_dim=config['belief_state_dim'],
            item_embedd_dim=config['item_embedd_dim'],
            rec_size=config['rec_size'],
            ranker=True,  # å‡è®¾ä½¿ç”¨ranker
            device=self.device,
            belief_lr=0.001,
            hidden_layers_reduction=[256],
            beliefs=['actor', 'critic']
        )
        
        return belief_encoder
    
    def load_ranker(self, env_name: str, ranker_type: str = "TopK", embedding_type: str = "ideal") -> Any:
        """
        åŠ è½½rankeræ¨¡å‹
        
        Args:
            env_name: ç¯å¢ƒåç§°
            ranker_type: rankerç±»å‹ (TopK, GeMS)
            embedding_type: embeddingç±»å‹
            
        Returns:
            ranker: Rankerå¯¹è±¡
        """
        config = self.env_configs[env_name]
        
        if ranker_type == "TopK":
            # åŠ è½½item embeddings
            item_embeddings = self.load_item_embeddings(env_name, embedding_type)
            
            ranker = TopKRanker(
                item_embeddings=item_embeddings,
                item_embedd_dim=config['item_embedd_dim'],
                rec_size=config['rec_size'],
                device=self.device
            )
            
        elif ranker_type == "GeMS":
            # åŠ è½½GeMS ranker
            item_embeddings = self.load_item_embeddings(env_name, embedding_type)

            ranker = GeMS(
                item_embeddings=item_embeddings,
                item_embedd_dim=config['item_embedd_dim'],
                rec_size=config['rec_size'],
                num_items=config['num_items'],
                latent_dim=32,  # latentç»´åº¦
                hidden_layers_infer=[512, 256],  # ä»checkpointæ¨æ–­ï¼š512 -> 256 -> 64
                hidden_layers_decoder=[256, 512],  # ä»checkpointæ¨æ–­ï¼š256 -> 512
                device=self.device,
                lambda_click=0.5,
                lambda_KL=0.5,
                lambda_prior=0.0,
                ranker_lr=0.001,
                fixed_embedds=False,  # ä¸å›ºå®šembeddings
                ranker_sample=False   # ä¸é‡‡æ ·ï¼Œä½¿ç”¨argmax
            )
            
            # å°è¯•åŠ è½½é¢„è®­ç»ƒçš„GeMSæƒé‡
            project_root = Path(__file__).resolve().parent.parent
            gems_checkpoint_path = project_root / "data" / "GeMS" / "checkpoints" / f"GeMS_{env_name}_latentdim32_beta1.0_lambdaclick0.5_lambdaprior0.0_scratch_seed58407201.ckpt"
            gems_checkpoint_path = str(gems_checkpoint_path)
            if os.path.exists(gems_checkpoint_path):
                try:
                    checkpoint = torch.load(gems_checkpoint_path, map_location=self.device)
                    ranker.load_state_dict(checkpoint['state_dict'])
                    print(f"âœ… æˆåŠŸåŠ è½½GeMS checkpoint: {gems_checkpoint_path}")
                except Exception as e:
                    print(f"âš ï¸ åŠ è½½GeMS checkpointå¤±è´¥: {e}")
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°GeMS checkpoint: {gems_checkpoint_path}")
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„rankerç±»å‹: {ranker_type}")
        
        return ranker
    
    def load_model(self, env_name: str, agent_type: str = "SAC", ranker_type: str = "TopK", 
                   embedding_type: str = "ideal") -> Tuple[Any, Any, Any]:
        """
        åŠ è½½å®Œæ•´çš„æ¨¡å‹ (load_agentçš„åˆ«åæ–¹æ³•)
        
        Args:
            env_name: ç¯å¢ƒåç§°
            agent_type: agentç±»å‹ (SAC, SlateQ, REINFORCE, WolpertingerSAC)
            ranker_type: rankerç±»å‹
            embedding_type: embeddingç±»å‹
            
        Returns:
            (agent, ranker, belief_encoder): æ¨¡å‹ç»„ä»¶
        """
        return self.load_agent(env_name, agent_type, ranker_type, embedding_type)
    
    def load_agent(self, env_name: str, agent_type: str = "SAC", ranker_type: str = "TopK", 
                   embedding_type: str = "ideal") -> Tuple[Any, Any, Any]:
        """
        åŠ è½½å®Œæ•´çš„agentæ¨¡å‹
        
        Args:
            env_name: ç¯å¢ƒåç§°
            agent_type: agentç±»å‹ (SAC, SlateQ, REINFORCE, WolpertingerSAC)
            ranker_type: rankerç±»å‹
            embedding_type: embeddingç±»å‹
            
        Returns:
            (agent, ranker, belief_encoder): æ¨¡å‹ç»„ä»¶
        """
        config = self.env_configs[env_name]
        
        # åŠ è½½ç»„ä»¶ (ç¡®ä¿ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´)
        # Belief Encoder: ä½¿ç”¨scratch embeddings (ä¸è®­ç»ƒæ—¶ä¸€è‡´)
        input_dim = config['rec_size'] * (config['item_embedd_dim'] + 1)  # 10 * (20 + 1) = 210
        belief_item_embeds = self.load_item_embeddings(env_name, "scratch")
        
        belief_encoder = GRUBelief(
            hidden_dim=config['belief_state_dim'],      # 20
            input_dim=input_dim,                        # 210
            item_embeddings=belief_item_embeds,
            belief_state_dim=config['belief_state_dim'],# 20
            item_embedd_dim=config['item_embedd_dim'],  # 20
            rec_size=config['rec_size'],                # 10
            ranker=True,  # ä¸è®­ç»ƒæ—¶ä¸€è‡´
            device=self.device,
            belief_lr=0.001,
            hidden_layers_reduction=[256],
            beliefs=['actor', 'critic']  # å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´
        )
        
        # Ranker: TopK+ideal
        ranker = self.load_ranker(env_name, ranker_type, embedding_type)
        
        # åˆ›å»ºagent (è¿ç»­åŠ¨ä½œSAC)
        if agent_type == "SAC":
            # æ ¹æ®rankerç±»å‹ç¡®å®šaction_dim
            if ranker_type == "GeMS":
                action_dim = 32  # GeMSçš„latent_dim
            else:
                action_dim = config['item_embedd_dim']  # TopKä½¿ç”¨item_embedd_dim

            agent = SAC(
                belief=belief_encoder,
                ranker=ranker,
                state_dim=config['belief_state_dim'],  # 20
                action_dim=action_dim,   # 32 for GeMS, 20 for TopK
                num_actions=1,  # å…³é”®ä¿®å¤: è¿ç»­SACæ¨¡å¼ï¼ŒQç½‘ç»œè¾“å‡ºç»´åº¦=1
                device=self.device,
                random_steps=1000,
                verbose=False,
                q_lr=0.001,
                pi_lr=0.003,
                gamma=0.8,
                tau=0.002,
                alpha=0.2,
                l2_reg=0.0,
                auto_entropy=True,
                alpha_lr=0.001,
                epsilon_start=1.0,
                epsilon_end=0.01,
                epsilon_decay=0.995,
                gradient_steps=1,
                hidden_layers_qnet=[256],
                hidden_layers_pinet=[256],
                target_update_frequency=1
            )
        
        elif agent_type == "SlateQ":
            agent = SlateQ(
                belief=belief_encoder,
                ranker=ranker,
                state_dim=config['belief_state_dim'],
                action_dim=config['num_items'],
                num_actions=config['num_items'],
                device=self.device,
                q_lr=0.001,
                gamma=0.8,
                epsilon_start=1.0,
                epsilon_end=0.01,
                epsilon_decay=0.995,
                hidden_layers_qnet=[256]
            )
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„agentç±»å‹: {agent_type}")
        # ğŸ¥ ç»Ÿä¸€åŠ è½½ checkpoint
        checkpoint_dir = self.models_dir  # best_models_for_data_collectionç›®å½•
        checkpoint_loaded = False

        for checkpoint_file in os.listdir(checkpoint_dir):
            # æ‰¾åˆ°åŒ¹é…å½“å‰ç¯å¢ƒçš„ checkpoint æ–‡ä»¶
            if checkpoint_file.endswith('.ckpt') and env_name in checkpoint_file:
                checkpoint_path = os.path.join(checkpoint_dir, checkpoint_file)
                try:
                    checkpoint = torch.load(checkpoint_path, map_location=self.device)
                    full_state_dict = checkpoint['state_dict']

                    print(f"ğŸ¥ å¼€å§‹ã€ç»Ÿä¸€åŠ è½½ã€‘: {checkpoint_path}")

                    # 1. è¿‡æ»¤æ‰è®­ç»ƒçŠ¶æ€ç›¸å…³çš„é”®ï¼ˆå¦‚ä¼˜åŒ–å™¨çŠ¶æ€ç­‰ï¼‰ï¼Œåªä¿ç•™æ¨¡å‹æƒé‡
                    model_keys_only = {
                        k: v for k, v in full_state_dict.items()
                        if not k.startswith(('q_optimizer.', 'pi_optimizer.', 'alpha_optimizer.', 'global_step', 'epoch'))
                    }

                    # 2. å°†æ‰€æœ‰æƒé‡ç»Ÿä¸€åŠ è½½åˆ° Agent å®ä¾‹ä¸­ (SAC å®ä¾‹åŒ…å« Ranker/Belief å­æ¨¡å—)
                    # strict=False ç”¨äºå¿½ç•¥è®­ç»ƒæ— å…³çš„é”®ï¼ˆå¦‚ä¼˜åŒ–å™¨çŠ¶æ€ï¼‰
                    load_result = agent.load_state_dict(model_keys_only, strict=False)

                    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ ¸å¿ƒç»„ä»¶ç¼ºå¤± (å¦‚æœæ¨¡å‹ç»“æ„ä¸ checkpoint ä¸ç¬¦ï¼Œå¯èƒ½ä¼šç¼ºå¤±)
                    core_missing = [k for k in load_result.missing_keys
                                    if k.startswith(('ranker.', 'belief.', 'QNet', 'PolicyNet'))]

                    if core_missing:
                         print(f"    ğŸš¨ è­¦å‘Š: Agent å†…éƒ¨æ ¸å¿ƒç»„ä»¶ç¼ºå¤± {len(core_missing)} ä¸ªé”®! è¯·æ£€æŸ¥æ¨¡å‹ç»“æ„ã€‚")
                         print(f"    ğŸš¨ ç¼ºå¤±é”®åç¤ºä¾‹: {core_missing[:5]}...")
                    else:
                         print(f"  âœ… Agent æ ¸å¿ƒæƒé‡åŠ è½½æˆåŠŸ (åŒ…å« Ranker/Belief).")

                    # 3. ã€å…³é”®ä¿®å¤ã€‘åŒæ­¥æƒé‡åˆ°å¤–éƒ¨ç‹¬ç«‹å®ä¾‹
                    # æ¨ç†æ—¶å¯èƒ½ä½¿ç”¨å¤–éƒ¨çš„ ranker/belief_encoder å®ä¾‹ï¼Œå¿…é¡»åŒæ­¥æƒé‡

                    # ä» Agent å†…éƒ¨çš„å­æ¨¡å—ä¸­æå–æ­£ç¡®çš„æƒé‡ï¼ŒåŠ è½½åˆ°å¤–éƒ¨ç‹¬ç«‹åˆ›å»ºçš„å®ä¾‹ä¸­
                    if ranker is not None:
                        external_ranker_state = agent.ranker.state_dict()
                        ranker.load_state_dict(external_ranker_state, strict=True)

                    external_belief_state = agent.belief.state_dict()
                    belief_encoder.load_state_dict(external_belief_state, strict=True)

                    print(f"  âœ… å¤–éƒ¨ Ranker/Belief å®ä¾‹æƒé‡å·²æˆåŠŸåŒæ­¥.")

                    # 4. ã€å…³é”®ä¿®å¤ã€‘è®¾ç½®action bounds
                    if 'action_center' in full_state_dict and 'action_scale' in full_state_dict:
                        agent.action_center = full_state_dict['action_center'].to(self.device)
                        agent.action_scale = full_state_dict['action_scale'].to(self.device)
                        print(f"  âœ… Action boundså·²ä»checkpointåŠ è½½: center shape={agent.action_center.shape}, scale shape={agent.action_scale.shape}")

                    elif ranker_type == "GeMS":
                        # ã€æ ¸å¿ƒä¿®å¤ã€‘åŠ¨æ€è®¡ç®—ç²¾ç¡®çš„ Action Boundsï¼Œè€Œä¸æ˜¯ä½¿ç”¨å›ºå®šçš„ 3.0
                        # è®­ç»ƒæ—¶ä»£ç æ˜¯è¿™æ ·åšçš„ï¼šranker.get_action_bounds(dataset_path)
                        
                        project_root = Path(__file__).resolve().parent.parent
                        # å‡è®¾æ•°æ®é›†è·¯å¾„ä¸ env_name å¯¹åº” (ä¾‹å¦‚ diffuse_topdown.pt)
                        # æ³¨æ„ï¼šè®­ç»ƒé…ç½®ä¸­ ranker_dataset é€šå¸¸å°±æ˜¯ env_name
                        dataset_path = project_root / "data" / "RecSim" / "datasets" / f"{env_name}.pt"
                        
                        if os.path.exists(dataset_path):
                            print(f"  ğŸ“Š æ­£åœ¨ä»æ•°æ®é›†è®¡ç®—ç²¾ç¡® Action Bounds: {dataset_path}")
                            # è¿™ä¼šè¿”å›ç²¾ç¡®çš„ (32,) å‘é‡
                            center, scale = ranker.get_action_bounds(str(dataset_path), batch_size=10)
                            
                            agent.action_center = center.to(self.device)
                            agent.action_scale = scale.to(self.device)
                            
                            print(f"  âœ… ç²¾ç¡® Bounds å·²åº”ç”¨!")
                            print(f"     Scale Mean: {scale.mean().item():.4f} (åº”æ¥è¿‘ 3.18)")
                            print(f"     Scale Std:  {scale.std().item():.4f}")
                        else:
                            print(f"  âš ï¸ æœªæ‰¾åˆ°æ•°æ®é›† {dataset_path}ï¼Œå›é€€åˆ°é»˜è®¤å€¼ 3.0 (æ€§èƒ½å¯èƒ½å—æŸ)")
                            agent.action_center = torch.zeros(action_dim, device=self.device)
                            agent.action_scale = 3.0 * torch.ones(action_dim, device=self.device)
                    else:
                        # å…¶ä»–æƒ…å†µä½¿ç”¨é»˜è®¤å€¼
                        agent.action_center = torch.zeros(action_dim, device=self.device)
                        agent.action_scale = torch.ones(action_dim, device=self.device)
                        print(f"  âš ï¸ ä½¿ç”¨é»˜è®¤action bounds: dim={action_dim}")

                    checkpoint_loaded = True
                    break

                except Exception as e:
                    print(f"âš ï¸ ç»Ÿä¸€åŠ è½½å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()

        if not checkpoint_loaded:
            print(f"âš ï¸ æœªæ‰¾åˆ°checkpointï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹")
            # åˆå§‹åŒ–é»˜è®¤çš„action bounds
            if ranker_type == "GeMS":
                agent.action_center = torch.zeros(action_dim, device=self.device)
                agent.action_scale = 3.0 * torch.ones(action_dim, device=self.device)
            else:
                agent.action_center = torch.zeros(action_dim, device=self.device)
                agent.action_scale = torch.ones(action_dim, device=self.device)
        
        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼å¹¶ç§»åˆ°GPU (è¿™éƒ¨åˆ†ä¿æŒä¸å˜)
        agent.eval()
        agent = agent.to(self.device)
        if ranker is not None:
            ranker.eval()
            ranker = ranker.to(self.device)
        belief_encoder.eval()
        belief_encoder = belief_encoder.to(self.device)
        
        return agent, ranker, belief_encoder
        # # ğŸ¥ æ‰‹æœ¯å¼åŠ è½½checkpoint
        # checkpoint_dir = self.models_dir  # best_models_for_data_collectionç›®å½•
        # checkpoint_loaded = False
        # for checkpoint_file in os.listdir(checkpoint_dir):
        #     if checkpoint_file.endswith('.ckpt') and env_name in checkpoint_file:
        #         checkpoint_path = os.path.join(checkpoint_dir, checkpoint_file)
        #         try:
        #             checkpoint = torch.load(checkpoint_path, map_location=self.device)
        #             full_state_dict = checkpoint['state_dict']
                    
        #             print(f"ğŸ¥ å¼€å§‹æ‰‹æœ¯å¼åŠ è½½: {checkpoint_path}")
        #             print(f"  æ€»é”®æ•°: {len(full_state_dict)}")
                    
        #             # 1. æå–å¹¶åŠ è½½Agentæƒé‡ (PolicyNet, QNetç­‰)
        #             agent_keys = {k: v for k, v in full_state_dict.items() 
        #                          if not k.startswith('belief.') and not k.startswith('ranker.')}
        #             agent_load_result = agent.load_state_dict(agent_keys, strict=False)
        #             print(f"  âœ… AgentåŠ è½½: {len(agent_keys)}ä¸ªé”®")
        #             if agent_load_result.missing_keys:
        #                 print(f"    ç¼ºå¤±: {len(agent_load_result.missing_keys)}ä¸ª")
        #                 print(f"    ç¼ºå¤±é”®å: {agent_load_result.missing_keys}") # <-- åŠ ä¸Šè¿™è¡Œ
                    
        #             # 2. æå–å¹¶åŠ è½½Beliefæƒé‡ (GRU, embeddingsç­‰)
        #             belief_keys = {k.replace('belief.', ''): v for k, v in full_state_dict.items() 
        #                           if k.startswith('belief.')}
        #             belief_load_result = belief_encoder.load_state_dict(belief_keys, strict=False)
        #             print(f"  âœ… BeliefåŠ è½½: {len(belief_keys)}ä¸ªé”®")
        #             if belief_load_result.missing_keys:
        #                 print(f"    ç¼ºå¤±: {len(belief_load_result.missing_keys)}ä¸ª")
        #                 print(f"    ç¼ºå¤±é”®å: {belief_load_result.missing_keys}")
                    
        #             # 3. éªŒè¯å…³é”®ç»„ä»¶æ˜¯å¦æˆåŠŸåŠ è½½
        #             agent_success = len(agent_load_result.missing_keys) == 0
        #             belief_success = len(belief_load_result.missing_keys) <= 2  # å…è®¸å°‘é‡ç¼ºå¤±
                    
        #             if agent_success and belief_success:
        #                 print(f"ğŸ‰ æ‰‹æœ¯å¼åŠ è½½æˆåŠŸ!")
        #             else:
        #                 print(f"âš ï¸ éƒ¨åˆ†åŠ è½½å¤±è´¥ - Agent: {agent_success}, Belief: {belief_success}")
                    
        #             checkpoint_loaded = True
        #             break
                    
        #         except Exception as e:
        #             print(f"âš ï¸ æ‰‹æœ¯å¼åŠ è½½å¤±è´¥: {e}")
        #             import traceback
        #             traceback.print_exc()
        
        # if not checkpoint_loaded:
        #     print(f"âš ï¸ æœªæ‰¾åˆ°checkpointï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹")
        
        # # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼å¹¶ç§»åˆ°GPU
        # agent.eval()
        # agent = agent.to(self.device)
        # if ranker is not None:
        #     ranker.eval()
        #     ranker = ranker.to(self.device)
        # belief_encoder.eval()
        # belief_encoder = belief_encoder.to(self.device)
        
        # return agent, ranker, belief_encoder

    
    def load_diffuse_models(self) -> Dict[str, Tuple[Any, Any, Any]]:
        """
        åŠ è½½æ‰€æœ‰diffuseç¯å¢ƒçš„æœ€ä¼˜æ¨¡å‹ï¼ˆSAC+GeMSï¼‰

        Returns:
            models: {env_name: (agent, ranker, belief_encoder)}
        """
        models = {}

        diffuse_envs = ['diffuse_topdown', 'diffuse_mix', 'diffuse_divpen']

        # ä½¿ç”¨SAC+GeMSæ¨¡å‹ç›®å½•
        sac_gems_models_dir = Path(__file__).resolve().parent / "sac_gems_models"

        for env_name in diffuse_envs:
            print(f"\nåŠ è½½ {env_name} ç¯å¢ƒçš„SAC+GeMSæ¨¡å‹...")
            try:
                # ä¸´æ—¶ä¿®æ”¹models_dirä¸ºSAC+GeMSç›®å½•
                original_models_dir = self.models_dir
                self.models_dir = str(sac_gems_models_dir / env_name)

                # åŠ è½½SAC+GeMSæ¨¡å‹
                agent, ranker, belief_encoder = self.load_agent(
                    env_name=env_name,
                    agent_type="SAC",
                    ranker_type="GeMS",  # ä½¿ç”¨GeMS ranker
                    embedding_type="scratch"  # GeMSä½¿ç”¨scratch embeddings
                )

                # æ¢å¤åŸå§‹models_dir
                self.models_dir = original_models_dir

                models[env_name] = (agent, ranker, belief_encoder)
                print(f"âœ… {env_name} SAC+GeMSæ¨¡å‹åŠ è½½æˆåŠŸ")
                print(f"   - AgentåŠ¨ä½œç»´åº¦: {agent.action_dim}")
                print(f"   - Rankerç±»å‹: {type(ranker).__name__}")
                print(f"   - Ranker latent_dim: {ranker.latent_dim if hasattr(ranker, 'latent_dim') else 'N/A'}")
            except Exception as e:
                print(f"âŒ {env_name} SAC+GeMSæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()

        return models

    def load_diffuse_models_topk(self) -> Dict[str, Tuple[Any, Any, Any]]:
        """
        åŠ è½½æ‰€æœ‰diffuseç¯å¢ƒçš„TopKæ¨¡å‹ï¼ˆæ—§æ–¹æ³•ï¼Œä»…ç”¨äºå¯¹æ¯”ï¼‰

        Returns:
            models: {env_name: (agent, ranker, belief_encoder)}
        """
        models = {}

        diffuse_envs = ['diffuse_topdown', 'diffuse_mix', 'diffuse_divpen']

        for env_name in diffuse_envs:
            print(f"\nåŠ è½½ {env_name} ç¯å¢ƒçš„TopKæ¨¡å‹...")
            try:
                agent, ranker, belief_encoder = self.load_agent(
                    env_name=env_name,
                    agent_type="SAC",
                    ranker_type="TopK",
                    embedding_type="ideal"
                )
                models[env_name] = (agent, ranker, belief_encoder)
                print(f"âœ… {env_name} TopKæ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                print(f"âŒ {env_name} TopKæ¨¡å‹åŠ è½½å¤±è´¥: {e}")

        return models

if __name__ == "__main__":
    # æµ‹è¯•æ¨¡å‹åŠ è½½
    print("æµ‹è¯•æ¨¡å‹åŠ è½½å™¨...")
    
    loader = ModelLoader()
    
    # æµ‹è¯•åŠ è½½å•ä¸ªç¯å¢ƒçš„æ¨¡å‹
    try:
        agent, ranker, belief_encoder = loader.load_agent(
            env_name="diffuse_topdown",
            agent_type="SAC",
            ranker_type="TopK",
            embedding_type="ideal"
        )
        print("âœ… å•ä¸ªæ¨¡å‹åŠ è½½æµ‹è¯•æˆåŠŸ")
        print(f"  Agentç±»å‹: {type(agent).__name__}")
        print(f"  Rankerç±»å‹: {type(ranker).__name__}")
        print(f"  Belief Encoderç±»å‹: {type(belief_encoder).__name__}")
    except Exception as e:
        print(f"âŒ å•ä¸ªæ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•åŠ è½½æ‰€æœ‰diffuseæ¨¡å‹
    try:
        models = loader.load_diffuse_models()
        print(f"\nâœ… æˆåŠŸåŠ è½½ {len(models)} ä¸ªç¯å¢ƒçš„æ¨¡å‹")
        for env_name in models.keys():
            print(f"  - {env_name}")
    except Exception as e:
        print(f"âŒ æ‰¹é‡æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    print("\nâœ… æ¨¡å‹åŠ è½½å™¨æµ‹è¯•å®Œæˆ!")
