#!/usr/bin/env python3
"""
ç”Ÿæˆç¦»çº¿æ•°æ®é›†æŠ¥å‘Š - è¯¦ç»†åˆ†æç‰ˆ
åˆ†ææ•°æ®é›†è´¨é‡ï¼Œè¯„ä¼°æ˜¯å¦é€‚åˆè®­ç»ƒç¦»çº¿å¼ºåŒ–å­¦ä¹ ç®—æ³•
"""
import os
import numpy as np
import sys
from pathlib import Path

def generate_report_from_npz(datasets_dir=None):
    """ç”Ÿæˆæ•°æ®é›†æŠ¥å‘Š

    Args:
        datasets_dir: æ•°æ®é›†ç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
    """
    if datasets_dir is None:
        # ä½¿ç”¨ç»Ÿä¸€è·¯å¾„é…ç½®
        project_root = Path(__file__).resolve().parent.parent.parent.parent.parent
        sys.path.insert(0, str(project_root / "config"))
        from paths import OFFLINE_DATASETS_DIR
        datasets_dir = str(OFFLINE_DATASETS_DIR)

    print("="*80)
    print("ç¦»çº¿å¼ºåŒ–å­¦ä¹ æ•°æ®é›†è¯¦ç»†åˆ†ææŠ¥å‘Š")
    print("="*80)

    # æ‰“å°æ•°æ®é›†è·¯å¾„ä¿¡æ¯
    print("\nğŸ“ æ•°æ®é›†è·¯å¾„ä¿¡æ¯:")
    print(f"  æ ¹ç›®å½•: {datasets_dir}")
    print(f"  æ•°æ®æ ¼å¼: D4RLæ ‡å‡†æ ¼å¼ (.npz)")
    print(f"  æ–‡ä»¶ç»“æ„:")
    print(f"    {datasets_dir}/")
    print(f"    â”œâ”€â”€ diffuse_topdown/")
    print(f"    â”‚   â””â”€â”€ expert_data_d4rl.npz")
    print(f"    â”œâ”€â”€ diffuse_mix/")
    print(f"    â”‚   â””â”€â”€ expert_data_d4rl.npz")
    print(f"    â””â”€â”€ diffuse_divpen/")
    print(f"        â””â”€â”€ expert_data_d4rl.npz")
    print(f"\n  NPZæ–‡ä»¶åŒ…å«å­—æ®µ:")
    print(f"    - observations: (N, 20) belief states")
    print(f"    - actions: (N, 32) latent actions")
    print(f"    - slates: (N, 10) discrete recommendations")
    print(f"    - rewards: (N,) immediate rewards")
    print(f"    - terminals: (N,) episodeç»ˆæ­¢æ ‡å¿—")
    print(f"    - clicks: (N, 10) ç”¨æˆ·ç‚¹å‡»è¡Œä¸º")
    print(f"    - diversity_scores: (N,) æ¨èå¤šæ ·æ€§")
    print(f"    - coverage_scores: (N,) ç‰©å“è¦†ç›–ç‡")
    print("="*80)

    # åœ¨çº¿æ€§èƒ½ï¼ˆåŸºå‡†ï¼Œç”¨äºè®¡ç®—æ€§èƒ½æ¯”ç‡ï¼‰
    # è¿™äº›æ˜¯è®­ç»ƒæ—¶çš„test rewardï¼Œç”¨äºè¯„ä¼°ç¦»çº¿æ•°æ®è´¨é‡
    online_performance = {
        'diffuse_topdown': 447.60,
        'diffuse_mix': 349.07,
        'diffuse_divpen': 296.73,
        'focused_topdown': 391.65,
        'focused_mix': 287.90,
        'focused_divpen': 299.80
    }

    results = []
    env_list = [
        'diffuse_topdown', 'diffuse_mix', 'diffuse_divpen',
        'focused_topdown', 'focused_mix', 'focused_divpen'
    ]

    print(f"\nğŸ” æ­£åœ¨æ‰«ææ•°æ®é›†...\n")

    for env_name in env_list:
        # ğŸ¯ å…³é”®ï¼šåªè¯»å– .npz æ–‡ä»¶
        npz_path = os.path.join(datasets_dir, env_name, 'expert_data_d4rl.npz')
        
        if os.path.exists(npz_path):
            try:
                # 1. åŠ è½½ NPZ (æå¿«)
                data = np.load(npz_path)
                
                # 2. æå–å…³é”®æ•°ç»„
                observations = data['observations']
                actions = data['actions']
                rewards = data['rewards']
                terminals = data['terminals']

                # æå–æ¨èç³»ç»Ÿç‰¹æœ‰æŒ‡æ ‡
                diversity_scores = data['diversity_scores'] if 'diversity_scores' in data else None
                coverage_scores = data['coverage_scores'] if 'coverage_scores' in data else None
                clicks = data['clicks'] if 'clicks' in data else None
                
                # 3. è®¡ç®—ç»Ÿè®¡æ•°æ®
                total_transitions = len(rewards)
                
                # è®¡ç®— Episode æ•°é‡å’Œå›æŠ¥
                # D4RLæ ¼å¼æ˜¯å¹³é“ºçš„ï¼Œéœ€è¦æ ¹æ® terminals (done=True) åˆ‡åˆ†
                episode_returns = []
                current_ep_return = 0
                current_ep_len = 0
                episode_lengths = []
                
                for i in range(total_transitions):
                    current_ep_return += rewards[i]
                    current_ep_len += 1
                    
                    # å¦‚æœé‡åˆ°ç»“æŸç¬¦ æˆ– æœ€åä¸€ä¸ªç‚¹
                    if terminals[i] or i == total_transitions - 1:
                        episode_returns.append(current_ep_return)
                        episode_lengths.append(current_ep_len)
                        current_ep_return = 0
                        current_ep_len = 0
                
                num_episodes = len(episode_returns)
                avg_return = np.mean(episode_returns) if episode_returns else 0
                std_return = np.std(episode_returns) if episode_returns else 0
                avg_len = np.mean(episode_lengths) if episode_lengths else 0
                
                # è®¡ç®—æ›´å¤šç»Ÿè®¡æŒ‡æ ‡
                non_zero_ratio = np.sum(rewards > 0) / total_transitions
                min_return = np.min(episode_returns) if episode_returns else 0
                max_return = np.max(episode_returns) if episode_returns else 0

                # è®¡ç®—rewardåˆ†å¸ƒ
                reward_mean = np.mean(rewards)
                reward_std = np.std(rewards)
                reward_min = np.min(rewards)
                reward_max = np.max(rewards)

                # è®¡ç®—ç‚¹å‡»ç‡
                if clicks is not None:
                    click_rate = np.mean(clicks)
                else:
                    click_rate = 0

                # 4. è·å–æ–‡ä»¶ç‰©ç†å¤§å°
                file_size_mb = os.path.getsize(npz_path) / (1024 * 1024)

                results.append({
                    'env_name': env_name,
                    'num_episodes': num_episodes,
                    'total_transitions': total_transitions,
                    'avg_episode_length': avg_len,
                    'avg_episode_return': avg_return,
                    'std_episode_return': std_return,
                    'min_episode_return': min_return,
                    'max_episode_return': max_return,
                    'file_size_mb': file_size_mb,
                    'non_zero_reward_ratio': non_zero_ratio,
                    'online_performance': online_performance.get(env_name, 0),
                    'diversity': np.mean(diversity_scores) if diversity_scores is not None else 0,
                    'coverage': np.mean(coverage_scores) if coverage_scores is not None else 0,
                    'click_rate': click_rate,
                    'reward_mean': reward_mean,
                    'reward_std': reward_std,
                    'reward_min': reward_min,
                    'reward_max': reward_max,
                    'obs_dim': observations.shape[1] if len(observations.shape) > 1 else 0,
                    'action_dim': actions.shape[1] if len(actions.shape) > 1 else 0,
                })
                
                print(f"âœ… {env_name}: åŠ è½½æˆåŠŸ | {num_episodes} eps | Avg Ret: {avg_return:.2f}")
                
            except Exception as e:
                print(f"âŒ {env_name}: NPZè§£æå¤±è´¥ - {e}")
        else:
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œé™é»˜è·³è¿‡æˆ–æ‰“å°æç¤º
            # print(f"âš ï¸ {env_name}: æœªæ‰¾åˆ° .npz æ–‡ä»¶")
            pass
            
    if not results:
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®ã€‚è¯·ç¡®è®¤ collect_data.py æ˜¯å¦æˆåŠŸæ‰§è¡Œå¹¶ç”Ÿæˆäº† .npz æ–‡ä»¶ã€‚")
        return

    # ================= ç”Ÿæˆè¯¦ç»†æŠ¥è¡¨ =================

    # 1. æ•°æ®é›†è§„æ¨¡ç»Ÿè®¡
    print("\n" + "="*80)
    print("ğŸ“Š è¡¨1ï¼šæ•°æ®é›†è§„æ¨¡ç»Ÿè®¡")
    print("="*80)
    print(f"| {'ç¯å¢ƒ':<18} | {'Episodes':<10} | {'Transitions':<12} | {'Avg Len':<8} | {'Size(MB)':<9} |")
    print("|" + "-"*78 + "|")

    total_episodes = 0
    total_transitions = 0
    total_size = 0

    for r in results:
        print(f"| {r['env_name']:<18} | {r['num_episodes']:<10,} | {r['total_transitions']:<12,} | {r['avg_episode_length']:<8.1f} | {r['file_size_mb']:<9.1f} |")
        total_episodes += r['num_episodes']
        total_transitions += r['total_transitions']
        total_size += r['file_size_mb']

    print("|" + "-"*78 + "|")
    print(f"| {'æ€»è®¡':<18} | {total_episodes:<10,} | {total_transitions:<12,} | {'-':<8} | {total_size:<9.1f} |")

    # 2. æ•°æ®è´¨é‡ä¸æ€§èƒ½å¯¹æ¯”
    print("\n" + "="*80)
    print("ğŸ“ˆ è¡¨2ï¼šæ•°æ®è´¨é‡ä¸åœ¨çº¿æ€§èƒ½å¯¹æ¯”")
    print("="*80)
    print(f"| {'ç¯å¢ƒ':<18} | {'å¹³å‡å›æŠ¥':<10} | {'æ ‡å‡†å·®':<8} | {'æœ€å°å€¼':<8} | {'æœ€å¤§å€¼':<8} | {'åœ¨çº¿æ€§èƒ½':<10} | {'æ¯”ç‡':<8} |")
    print("|" + "-"*98 + "|")

    for r in results:
        ratio = (r['avg_episode_return'] / r['online_performance'] * 100) if r['online_performance'] > 0 else 0
        print(f"| {r['env_name']:<18} | {r['avg_episode_return']:<10.2f} | {r['std_episode_return']:<8.2f} | {r['min_episode_return']:<8.2f} | {r['max_episode_return']:<8.2f} | {r['online_performance']:<10.2f} | {ratio:<7.1f}% |")

    # 3. æ¨èç³»ç»Ÿç‰¹æœ‰æŒ‡æ ‡
    print("\n" + "="*80)
    print("ğŸ¯ è¡¨3ï¼šæ¨èç³»ç»ŸæŒ‡æ ‡ (Diversity & Coverage & Click Rate)")
    print("="*80)
    print(f"| {'ç¯å¢ƒ':<18} | {'Diversity':<11} | {'Coverage':<10} | {'ç‚¹å‡»ç‡':<10} | {'éé›¶å¥–åŠ±':<10} |")
    print("|" + "-"*78 + "|")

    for r in results:
        print(f"| {r['env_name']:<18} | {r['diversity']:<11.4f} | {r['coverage']:<10.4f} | {r['click_rate']*100:<9.2f}% | {r['non_zero_reward_ratio']*100:<9.1f}% |")

    # 4. æ•°æ®ç»´åº¦ä¿¡æ¯
    print("\n" + "="*80)
    print("ğŸ”¢ è¡¨4ï¼šæ•°æ®ç»´åº¦ä¿¡æ¯")
    print("="*80)
    print(f"| {'ç¯å¢ƒ':<18} | {'Obsç»´åº¦':<10} | {'Actionç»´åº¦':<12} | {'è¯´æ˜':<30} |")
    print("|" + "-"*88 + "|")

    for r in results:
        print(f"| {r['env_name']:<18} | {r['obs_dim']:<10} | {r['action_dim']:<12} | {'belief_state + latent_action':<30} |")


    # ================= ç¦»çº¿RLé€‚ç”¨æ€§åˆ†æ =================
    print("\n" + "="*80)
    print("ğŸ¤– ç¦»çº¿å¼ºåŒ–å­¦ä¹ é€‚ç”¨æ€§åˆ†æ")
    print("="*80)

    print("\n1ï¸âƒ£ æ•°æ®è§„æ¨¡è¯„ä¼°:")
    print(f"   æ€»Episodes: {total_episodes:,} ä¸ª")
    print(f"   æ€»Transitions: {total_transitions:,} ä¸ª ({total_transitions/1e6:.1f}M)")

    if total_transitions >= 1_000_000:
        print(f"   âœ… æ•°æ®è§„æ¨¡å……è¶³ (>100ä¸‡æ¡)")
        print(f"      - è¶³å¤Ÿè®­ç»ƒTD3+BCã€CQLã€IQLç­‰ç¦»çº¿RLç®—æ³•")
        print(f"      - å¯ä»¥æ”¯æŒå¤šæ¬¡è®­ç»ƒå’Œè¶…å‚æ•°è°ƒä¼˜")
    elif total_transitions >= 100_000:
        print(f"   âš ï¸ æ•°æ®è§„æ¨¡ä¸­ç­‰ (10-100ä¸‡æ¡)")
        print(f"      - å¯ä»¥è®­ç»ƒç¦»çº¿RLï¼Œä½†å¯èƒ½éœ€è¦æ›´å¤šæ•°æ®å¢å¼º")
    else:
        print(f"   âŒ æ•°æ®è§„æ¨¡ä¸è¶³ (<10ä¸‡æ¡)")
        print(f"      - å»ºè®®æ”¶é›†æ›´å¤šæ•°æ®")

    print("\n2ï¸âƒ£ æ•°æ®è´¨é‡è¯„ä¼°:")
    avg_ratio = np.mean([r['avg_episode_return'] / r['online_performance'] * 100
                         for r in results if r['online_performance'] > 0])
    print(f"   å¹³å‡æ€§èƒ½æ¯”ç‡: {avg_ratio:.1f}%")

    if avg_ratio >= 70:
        print(f"   âœ… Expertçº§åˆ«æ•°æ® (70-90%)")
        print(f"      - é«˜è´¨é‡ä¸“å®¶æ•°æ®ï¼Œé€‚åˆBehavior Cloning")
        print(f"      - é€‚åˆConservative Q-Learning (CQL)")
        print(f"      - é€‚åˆTD3+BCç­‰ç®—æ³•")
    elif avg_ratio >= 40:
        print(f"   âœ… Mediumçº§åˆ«æ•°æ® (40-70%)")
        print(f"      - ä¸­ç­‰è´¨é‡æ•°æ®ï¼Œé€‚åˆå¤§å¤šæ•°ç¦»çº¿RLç®—æ³•")
    else:
        print(f"   âš ï¸ ä½è´¨é‡æ•°æ® (<40%)")
        print(f"      - å¯èƒ½éœ€è¦æ›´å¼ºçš„æ­£åˆ™åŒ–")

    print("\n3ï¸âƒ£ æ•°æ®å¤šæ ·æ€§è¯„ä¼°:")
    avg_diversity = np.mean([r['diversity'] for r in results])
    avg_std = np.mean([r['std_episode_return'] for r in results])
    print(f"   å¹³å‡Diversity: {avg_diversity:.4f}")
    print(f"   å¹³å‡æ ‡å‡†å·®: {avg_std:.2f}")

    if avg_diversity > 0.85 and avg_std > 30:
        print(f"   âœ… æ•°æ®å¤šæ ·æ€§è‰¯å¥½")
        print(f"      - æ¨èå¤šæ ·æ€§é«˜ï¼Œè¦†ç›–ä¸åŒç­–ç•¥è¡Œä¸º")
        print(f"      - å›æŠ¥æ ‡å‡†å·®åˆç†ï¼ŒåŒ…å«ä¸åŒè´¨é‡è½¨è¿¹")
    else:
        print(f"   âš ï¸ æ•°æ®å¤šæ ·æ€§å¯èƒ½ä¸è¶³")

    print("\n4ï¸âƒ£ æ¨èç®—æ³•å»ºè®®:")
    print(f"   åŸºäºå½“å‰æ•°æ®è´¨é‡ ({avg_ratio:.1f}%)ï¼Œæ¨èä»¥ä¸‹ç®—æ³•:")
    print(f"   ")
    print(f"   ğŸ¥‡ é¦–é€‰: TD3+BC")
    print(f"      - é€‚åˆé«˜è´¨é‡expertæ•°æ®")
    print(f"      - ç®€å•æœ‰æ•ˆï¼Œæ˜“äºè°ƒå‚")
    print(f"      - è®ºæ–‡: Fujimoto & Gu, 2021")
    print(f"   ")
    print(f"   ğŸ¥ˆ æ¬¡é€‰: Conservative Q-Learning (CQL)")
    print(f"      - é€‚åˆå„ç§è´¨é‡çš„æ•°æ®")
    print(f"      - å¼ºå¤§çš„åˆ†å¸ƒå¤–åŠ¨ä½œæƒ©ç½š")
    print(f"      - è®ºæ–‡: Kumar et al., 2020")
    print(f"   ")
    print(f"   ğŸ¥‰ å¤‡é€‰: Implicit Q-Learning (IQL)")
    print(f"      - æ— éœ€æ˜¾å¼ç­–ç•¥çº¦æŸ")
    print(f"      - é€‚åˆå¤šæ¨¡æ€æ•°æ®")
    print(f"      - è®ºæ–‡: Kostrikov et al., 2021")

    print("\n5ï¸âƒ£ æ•°æ®æ ¼å¼å…¼å®¹æ€§:")
    print(f"   âœ… D4RLæ ‡å‡†æ ¼å¼")
    print(f"   âœ… åŒ…å«observations, actions, rewards, terminals")
    print(f"   âœ… å¯ç›´æ¥ç”¨äºd3rlpyã€rlkitç­‰ç¦»çº¿RLåº“")
    print(f"   âœ… ç»´åº¦: obs={results[0]['obs_dim']}ç»´, action={results[0]['action_dim']}ç»´")

    print("\n" + "="*80)
    print("âœ… æ€»ç»“: æ•°æ®é›†è´¨é‡ä¼˜ç§€ï¼Œå®Œå…¨æ”¯æŒç¦»çº¿å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼")
    print("="*80)

if __name__ == "__main__":
    generate_report_from_npz()