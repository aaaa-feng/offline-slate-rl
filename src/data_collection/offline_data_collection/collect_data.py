#!/usr/bin/env python3
"""
ä¸»æ•°æ®æ”¶é›†è„šæœ¬
ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹æ”¶é›†ç¦»çº¿å¼ºåŒ–å­¦ä¹ æ•°æ®
"""
import torch
import numpy as np
import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Tuple, Optional
from tqdm import tqdm
import argparse
from datetime import datetime

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥ä¾¿å¯¼å…¥coreæ¨¡å—
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from core.data_formats import SlateDataset, SlateTrajectory, SlateTransition, SlateObservation, SlateAction, SlateInfo
from core.model_loader import ModelLoader
from core.environment_factory import EnvironmentFactory
from core.metrics import SlateMetrics, create_item_popularity_dict

class OfflineDataCollector:
    """ç¦»çº¿æ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self, output_dir: str = None):
        # åŠ¨æ€è®¾ç½®é»˜è®¤è¾“å‡ºç›®å½•
        if output_dir is None:
            # ä½¿ç”¨ç»Ÿä¸€è·¯å¾„é…ç½®
            project_root = Path(__file__).resolve().parent.parent.parent.parent.parent
            sys.path.insert(0, str(project_root / "config"))
            from paths import OFFLINE_DATASETS_DIR
            output_dir = str(OFFLINE_DATASETS_DIR)
        self.output_dir = output_dir
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.model_loader = ModelLoader()
        self.env_factory = EnvironmentFactory()
        
        # æ•°æ®æ”¶é›†é…ç½®
        self.collection_config = {
            'expert': {
                'episodes': 10000,
                'description': 'Expert trajectories from best performing models'
            },
            'medium': {
                'episodes': 10000, 
                'description': 'Medium quality trajectories from decent models'
            },
            'random': {
                'episodes': 5000,
                'description': 'Random trajectories for baseline'
            }
        }
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        Path(self.output_dir).mkdir(parents=True, exist_ok=True)
    
    def collect_trajectories_from_model(self, env_name: str, agent, ranker, belief_encoder,
                                      environment, num_episodes: int,
                                      quality_level: str = "expert",
                                      save_raw_obs: bool = False) -> SlateDataset:
        """
        ä½¿ç”¨æŒ‡å®šæ¨¡å‹æ”¶é›†è½¨è¿¹æ•°æ®

        Args:
            env_name: ç¯å¢ƒåç§°
            agent: RLæ™ºèƒ½ä½“
            ranker: æ’åºå™¨
            belief_encoder: ä¿¡å¿µç¼–ç å™¨
            environment: ç¯å¢ƒå®ä¾‹
            num_episodes: æ”¶é›†çš„episodeæ•°é‡
            quality_level: æ•°æ®è´¨é‡çº§åˆ«
            save_raw_obs: æ˜¯å¦ä¿å­˜åŸå§‹obs (é»˜è®¤Falseï¼Œå‘åå…¼å®¹)

        Returns:
            dataset: æ”¶é›†çš„æ•°æ®é›†
        """
        print(f"å¼€å§‹æ”¶é›† {env_name} ç¯å¢ƒçš„ {quality_level} æ•°æ®...")
        print(f"ç›®æ ‡episodes: {num_episodes}")
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = SlateDataset(f"{env_name}_{quality_level}")
        dataset.metadata = {
            'env_name': env_name,
            'quality_level': quality_level,
            'agent_type': type(agent).__name__,
            'ranker_type': type(ranker).__name__ if ranker else 'None',
            'collection_time': datetime.now().isoformat(),
            'device': str(self.device)
        }
        
        # åˆå§‹åŒ–æŒ‡æ ‡è®¡ç®—å™¨
        env_config = self.env_factory.get_env_config(env_name)
        
        # åŠ è½½ç‰©å“embeddingsç”¨äºæŒ‡æ ‡è®¡ç®—
        project_root = Path(__file__).resolve().parent.parent.parent.parent.parent
        sys.path.insert(0, str(project_root / "config"))
        from paths import get_embeddings_path
        item_embeddings_path = str(get_embeddings_path(env_config['env_embedds']))
        if os.path.exists(item_embeddings_path):
            item_embeddings = torch.load(item_embeddings_path, map_location=self.device)
        else:
            # ä½¿ç”¨éšæœºembeddings
            item_embeddings = torch.randn(env_config['num_items'], env_config['item_embedd_dim'])
        
        metrics_calculator = SlateMetrics(item_embeddings, env_config['num_items'])
        
        # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼ (å¦‚æœæ¨¡å‹ä¸ä¸ºNone)
        if agent is not None:
            agent.eval()
        if ranker is not None:
            ranker.eval()
        if belief_encoder is not None:
            belief_encoder.eval()
        
        # æ”¶é›†æ•°æ®
        successful_episodes = 0
        failed_episodes = 0
        
        with torch.no_grad():
            for episode_idx in tqdm(range(num_episodes), desc=f"æ”¶é›†{quality_level}æ•°æ®"):
                try:
                    trajectory = self._collect_single_episode(
                        environment, agent, ranker, belief_encoder,
                        metrics_calculator, episode_idx, quality_level, save_raw_obs
                    )
                    
                    if trajectory and len(trajectory.transitions) > 0:
                        dataset.add_trajectory(trajectory)
                        successful_episodes += 1
                    else:
                        failed_episodes += 1
                        
                except Exception as e:
                    print(f"Episode {episode_idx} æ”¶é›†å¤±è´¥: {e}")
                    failed_episodes += 1
                    continue
                
                # æ¯1000ä¸ªepisodeæ‰“å°ä¸€æ¬¡è¿›åº¦
                if (episode_idx + 1) % 1000 == 0:
                    stats = dataset.get_stats()
                    print(f"å·²å®Œæˆ {episode_idx + 1}/{num_episodes} episodes")
                    print(f"  æˆåŠŸ: {successful_episodes}, å¤±è´¥: {failed_episodes}")
                    print(f"  å¹³å‡episodeé•¿åº¦: {stats.get('avg_episode_length', 0):.2f}")
                    print(f"  å¹³å‡episodeå›æŠ¥: {stats.get('avg_episode_return', 0):.2f}")
        
        print(f"æ•°æ®æ”¶é›†å®Œæˆ!")
        print(f"  æˆåŠŸepisodes: {successful_episodes}")
        print(f"  å¤±è´¥episodes: {failed_episodes}")
        print(f"  æˆåŠŸç‡: {successful_episodes/(successful_episodes+failed_episodes)*100:.2f}%")
        
        return dataset
    
    def _collect_single_episode(self, environment, agent, ranker, belief_encoder,
                               metrics_calculator, episode_id: int, quality_level: str = "expert",
                               save_raw_obs: bool = False) -> Optional[SlateTrajectory]:
        """
        æ”¶é›†å•ä¸ªepisodeçš„æ•°æ®

        Returns:
            trajectory: è½¨è¿¹æ•°æ®ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            # é‡ç½®ç¯å¢ƒ
            obs, info = environment.reset()

            # V2æ–°å¢ï¼šä¿å­˜åŸå§‹obsï¼ˆå¼€å…³æ§åˆ¶ï¼‰
            import copy
            raw_obs_before_encoding = copy.deepcopy(obs) if save_raw_obs else None

            # åˆå§‹åŒ–è½¨è¿¹
            trajectory = SlateTrajectory()

            # åˆå§‹åŒ–ä¿¡å¿µçŠ¶æ€ (å¦‚æœæœ‰belief_encoder)
            # å…³é”®ä¿®å¤ï¼šä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼Œç¬¬ä¸€æ¬¡è°ƒç”¨belief.forward(obs)å°†åŸå§‹obsè½¬æ¢ä¸ºbelief state
            if belief_encoder is not None:
                # æ‰‹åŠ¨é‡ç½®GRUçš„hiddençŠ¶æ€
                for module in belief_encoder.beliefs:
                    belief_encoder.hidden[module] = torch.zeros(1, 1, belief_encoder.hidden_dim, device=belief_encoder.my_device)
                # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šå°†åŸå§‹obsè½¬æ¢ä¸ºbelief state
                obs = belief_encoder.forward(obs)

            episode_slates = []  # ç”¨äºè®¡ç®—è¦†ç›–ç‡
            done = False
            timestep = 0

            while not done and timestep < 100:  # æœ€å¤§100æ­¥
                # å…³é”®ä¿®å¤ï¼šobså·²ç»æ˜¯belief stateï¼Œç›´æ¥ä½¿ç”¨
                current_belief_state = obs.clone().detach() if belief_encoder is not None else obs

                # åˆ›å»ºè§‚å¯Ÿï¼ˆV2ï¼šå¼€å…³æ§åˆ¶raw_obsä¿å­˜ï¼‰
                observation = SlateObservation(
                    belief_state=current_belief_state,
                    raw_obs=raw_obs_before_encoding  # æ ¹æ®save_raw_obså¼€å…³å†³å®šæ˜¯å¦ä¿å­˜
                )

                # é€‰æ‹©åŠ¨ä½œ (å¦‚æœæ¨¡å‹ä¸ºNoneï¼Œä½¿ç”¨éšæœºç­–ç•¥)
                latent_action = None  # åˆå§‹åŒ–latent_action

                if agent is None or ranker is None or quality_level == "random":
                    # éšæœºåŠ¨ä½œ
                    slate = environment.get_random_action()
                    latent_action = None  # éšæœºç­–ç•¥æ²¡æœ‰latent action
                else:
                    # ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹
                    if ranker:
                        # å…³é”®ä¿®å¤ï¼šä¿å­˜latent_action
                        latent_action = agent.get_action(current_belief_state, sample=False)
                        slate = ranker.rank(latent_action)
                        # å…³é”®ï¼šclone + detaché¿å…æ¢¯åº¦é—®é¢˜
                        latent_action = latent_action.clone().detach()
                    else:
                        slate = agent.get_action(current_belief_state, sample=False)
                        latent_action = None  # æ²¡æœ‰rankeræ—¶ï¼Œactionå°±æ˜¯slate

                # ç¡®ä¿slateæ˜¯tensoræ ¼å¼ (ç¯å¢ƒéœ€è¦tensor)
                if isinstance(slate, list):
                    slate = torch.tensor(slate, device=self.device)
                elif isinstance(slate, np.ndarray):
                    slate = torch.tensor(slate, device=self.device)
                elif torch.is_tensor(slate):
                    slate = slate.to(self.device)

                # åˆ›å»ºåŠ¨ä½œ (SlateActionéœ€è¦åˆ—è¡¨æ ¼å¼)
                slate_list = slate.cpu().tolist() if torch.is_tensor(slate) else slate
                # å…³é”®ä¿®å¤ï¼šä¿å­˜latent_action
                action = SlateAction(
                    discrete_slate=slate_list,
                    latent_action=latent_action  # ä¿å­˜latent action
                )

                # ç¯å¢ƒæ­¥è¿›
                next_obs_raw, reward, done, next_info = environment.step(slate)

                # V2æ–°å¢ï¼šä¿å­˜next_raw_obsï¼ˆå¼€å…³æ§åˆ¶ï¼‰
                next_raw_obs_copy = copy.deepcopy(next_obs_raw) if save_raw_obs else None

                # ä¿å­˜åŸå§‹è§‚å¯Ÿä¸­çš„clicksï¼ˆåœ¨è½¬æ¢ä¸ºbelief stateä¹‹å‰ï¼‰
                clicks = next_obs_raw.get('clicks', torch.zeros(len(slate)))
                if not torch.is_tensor(clicks):
                    clicks = torch.tensor(clicks)

                # V3æ–°å¢ï¼šè·å–Oracleä¿¡æ¯ï¼ˆå¼€å…³æ§åˆ¶ï¼‰
                item_relevances = None
                if save_raw_obs:
                    try:
                        # ä»åº•å±‚æ¨¡æ‹Ÿå™¨è·å–çœŸå®ç›¸å…³æ€§ï¼ˆä¸Šå¸è§†è§’ï¼‰
                        item_relevances = environment.get_relevances()
                        if item_relevances is not None and torch.is_tensor(item_relevances):
                            item_relevances = item_relevances.clone().detach()
                    except (AttributeError, Exception) as e:
                        # å¦‚æœç¯å¢ƒä¸æ”¯æŒget_relevancesï¼Œé™é»˜è·³è¿‡
                        item_relevances = None

                # å…³é”®ä¿®å¤ï¼šä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼Œè°ƒç”¨belief.forward(next_obs, done)æ›´æ–°belief state
                if belief_encoder is not None:
                    next_obs = belief_encoder.forward(next_obs_raw, done=done)
                    # å½“done=Trueæ—¶ï¼Œbelief_encoderå¯èƒ½è¿”å›Noneï¼Œä½¿ç”¨å½“å‰obsä½œä¸ºnext_belief_state
                    if next_obs is None:
                        next_belief_state = obs.clone().detach()
                    else:
                        next_belief_state = next_obs.clone().detach()
                else:
                    next_obs = next_obs_raw
                    next_belief_state = next_obs

                next_observation = SlateObservation(
                    belief_state=next_belief_state,
                    raw_obs=next_raw_obs_copy  # V2ï¼šæ ¹æ®å¼€å…³å†³å®šæ˜¯å¦ä¿å­˜
                )
                
                episode_slates.append(slate_list)
                diversity_score = metrics_calculator.calculate_diversity_score(slate_list)
                coverage_score = metrics_calculator.calculate_coverage_score(slate_list, episode_slates)
                
                # åˆ›å»ºä¿¡æ¯
                info_data = SlateInfo(
                    clicks=clicks,
                    diversity_score=diversity_score,
                    coverage_score=coverage_score,
                    episode_return=0.0,  # å°†åœ¨è½¨è¿¹å®Œæˆåæ›´æ–°
                    episode_id=episode_id,
                    timestep=timestep,
                    item_relevances=item_relevances  # V3ï¼šOracleä¿¡æ¯
                )
                
                # åˆ›å»ºè½¬ç§»
                transition = SlateTransition(
                    observation=observation,
                    action=action,
                    reward=float(reward),
                    next_observation=next_observation,
                    done=done,
                    info=info_data
                )
                
                trajectory.add_transition(transition)

                # æ›´æ–°çŠ¶æ€
                obs = next_obs
                raw_obs_before_encoding = next_raw_obs_copy  # V2ï¼šæ›´æ–°raw_obs
                timestep += 1
            
            # æ›´æ–°æ‰€æœ‰è½¬ç§»çš„episode_return
            episode_return = trajectory.get_return()
            for transition in trajectory.transitions:
                transition.info.episode_return = episode_return
            
            return trajectory
            
        except Exception as e:
            print(f"æ”¶é›†episode {episode_id} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _get_belief_state(self, obs: Dict, belief_encoder) -> torch.Tensor:
        """
        è·å–belief state

        Args:
            obs: ç¯å¢ƒè§‚å¯Ÿ
            belief_encoder: ä¿¡å¿µç¼–ç å™¨

        Returns:
            belief_state: ä¿¡å¿µçŠ¶æ€å‘é‡
        """
        try:
            if belief_encoder is not None:
                # ä½¿ç”¨GRUBeliefçš„forwardæ–¹æ³•
                belief_state = belief_encoder.forward(obs, done=False)
                # å…³é”®ä¿®å¤ï¼šclone + detach é¿å…inference modeå†²çª
                if belief_state is not None:
                    belief_state = belief_state.clone().detach().to(self.device)
                    return belief_state
                else:
                    return torch.zeros(32, device=self.device)
            else:
                # å¦‚æœæ²¡æœ‰belief encoderï¼Œè¿”å›éšæœºå‘é‡
                return torch.randn(32, device=self.device)
        except Exception as e:
            print(f"è·å–belief stateæ—¶å‡ºé”™: {e}")
            return torch.zeros(32, device=self.device)
    
    def collect_all_diffuse_data(self, quality_level: str = 'expert', save_raw_obs: bool = False):
        """
        æ”¶é›†æ‰€æœ‰diffuseç¯å¢ƒçš„æ•°æ®

        Args:
            quality_level: æ•°æ®è´¨é‡çº§åˆ« (expert/medium/random)
            save_raw_obs: æ˜¯å¦ä¿å­˜åŸå§‹obs (é»˜è®¤Falseï¼Œå‘åå…¼å®¹)
        """
        print(f"å¼€å§‹æ”¶é›†æ‰€æœ‰diffuseç¯å¢ƒçš„ {quality_level} æ•°æ®...")

        # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        print(f"åŠ è½½ {quality_level} çº§åˆ«çš„æ¨¡å‹...")
        models = self.model_loader.load_diffuse_models(quality_level=quality_level)
        
        # åˆ›å»ºç¯å¢ƒ (éœ€è¦åˆ‡æ¢åˆ°GeMSæ ¹ç›®å½•ï¼Œå› ä¸ºTopicRecä½¿ç”¨ç›¸å¯¹è·¯å¾„)
        print("åˆ›å»ºç¯å¢ƒ...")
        original_cwd = os.getcwd()
        project_root = Path(__file__).resolve().parent.parent
        try:
            os.chdir(str(project_root))
            environments = self.env_factory.create_all_diffuse_environments()
        finally:
            os.chdir(original_cwd)
        
        # ä¸ºæ¯ä¸ªç¯å¢ƒæ”¶é›†æ•°æ®
        for env_name in ['diffuse_topdown', 'diffuse_mix', 'diffuse_divpen']:
            if env_name not in models or env_name not in environments:
                print(f"âš ï¸ è·³è¿‡ {env_name}: æ¨¡å‹æˆ–ç¯å¢ƒç¼ºå¤±")
                continue
            
            print(f"\n{'='*60}")
            print(f"æ”¶é›† {env_name} ç¯å¢ƒçš„æ•°æ®")
            print(f"{'='*60}")
            
            agent, ranker, belief_encoder = models[env_name]
            environment = environments[env_name]

            # æ”¶é›†æŒ‡å®šè´¨é‡çº§åˆ«çš„æ•°æ®
            dataset = self.collect_trajectories_from_model(
                env_name, agent, ranker, belief_encoder, environment,
                self.collection_config[quality_level]['episodes'], quality_level, save_raw_obs
            )

            # ä¿å­˜æ•°æ®
            data_path = os.path.join(self.output_dir, env_name, f'{quality_level}_data.pkl')
            dataset.save(data_path, format='pickle')

            # ä¿å­˜D4RLæ ¼å¼
            d4rl_path = os.path.join(self.output_dir, env_name, f'{quality_level}_data_d4rl.npz')
            dataset.save(d4rl_path, format='d4rl')

            print(f"âœ… {env_name} {quality_level}æ•°æ®å·²ä¿å­˜:")
            print(f"  Pickleæ ¼å¼: {data_path}")
            print(f"  D4RLæ ¼å¼: {d4rl_path}")

            # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
            stats = dataset.get_stats()
            print(f"  æ•°æ®é›†ç»Ÿè®¡:")
            for key, value in stats.items():
                print(f"    {key}: {value}")
        
        print(f"\nğŸ‰ æ‰€æœ‰æ•°æ®æ”¶é›†å®Œæˆ!")
        print(f"æ•°æ®ä¿å­˜åœ¨: {self.output_dir}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç¦»çº¿æ•°æ®æ”¶é›†')
    # åŠ¨æ€è®¾ç½®é»˜è®¤è¾“å‡ºç›®å½•
    project_root = Path(__file__).resolve().parent.parent.parent.parent.parent
    default_output_dir = str(project_root / "data" / "datasets" / "offline")
    parser.add_argument('--output_dir', type=str,
                       default=default_output_dir,
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--env_name', type=str,
                       choices=['diffuse_topdown', 'diffuse_mix', 'diffuse_divpen',
                               'focused_topdown', 'focused_mix', 'focused_divpen', 'all'],
                       default='all',
                       help='ç¯å¢ƒåç§°')
    parser.add_argument('--episodes', type=int, default=10000,
                       help='æ¯ä¸ªè´¨é‡çº§åˆ«çš„episodesæ•°é‡')
    parser.add_argument('--quality', type=str,
                       choices=['expert', 'medium', 'random'],
                       default='expert',
                       help='æ•°æ®è´¨é‡çº§åˆ« (expert/medium/random)')
    parser.add_argument('--save_raw_obs', action='store_true',
                       help='ä¿å­˜åŸå§‹ç¯å¢ƒè§‚å¯Ÿ(V2æ ¼å¼)')
    parser.add_argument('--gpu', type=int, default=None,
                       help='æŒ‡å®šä½¿ç”¨çš„GPUç¼–å·')

    args = parser.parse_args()

    # è®¾ç½®GPU
    if args.gpu is not None:
        os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu)
        print(f"è®¾ç½®ä½¿ç”¨GPU: {args.gpu}")
    
    # åˆ›å»ºæ•°æ®æ”¶é›†å™¨
    collector = OfflineDataCollector(args.output_dir)
    
    # æ›´æ–°é…ç½®
    for quality in collector.collection_config:
        collector.collection_config[quality]['episodes'] = args.episodes
    
    if args.env_name == 'all':
        # æ”¶é›†æ‰€æœ‰ç¯å¢ƒçš„æ•°æ®
        collector.collect_all_diffuse_data(quality_level=args.quality, save_raw_obs=args.save_raw_obs)
    else:
        # æ”¶é›†å•ä¸ªç¯å¢ƒçš„æ•°æ®
        print(f"æ”¶é›† {args.env_name} ç¯å¢ƒçš„ {args.quality} æ•°æ®...")

        # æ ¹æ®ç¯å¢ƒåç§°åˆ¤æ–­æ˜¯diffuseè¿˜æ˜¯focused
        is_focused = args.env_name.startswith('focused')

        # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        print(f"åŠ è½½ {args.quality} çº§åˆ«çš„æ¨¡å‹...")
        if is_focused:
            models = collector.model_loader.load_focused_models(quality_level=args.quality)
        else:
            models = collector.model_loader.load_diffuse_models(quality_level=args.quality)

        if args.env_name not in models:
            print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ° {args.env_name} çš„æ¨¡å‹")
            return

        # åˆ›å»ºç¯å¢ƒ
        print("åˆ›å»ºç¯å¢ƒ...")
        original_cwd = os.getcwd()
        project_root = Path(__file__).resolve().parent.parent
        try:
            os.chdir(str(project_root))
            environment = collector.env_factory.create_environment(args.env_name)
        finally:
            os.chdir(original_cwd)

        if environment is None:
            print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ° {args.env_name} çš„ç¯å¢ƒ")
            return

        print(f"\n{'='*60}")
        print(f"æ”¶é›† {args.env_name} ç¯å¢ƒçš„æ•°æ®")
        print(f"{'='*60}")

        agent, ranker, belief_encoder = models[args.env_name]
        # environmentå·²ç»åœ¨ä¸Šé¢åˆ›å»ºå¥½äº†

        # æ”¶é›†æŒ‡å®šè´¨é‡çº§åˆ«çš„æ•°æ®
        dataset = collector.collect_trajectories_from_model(
            args.env_name, agent, ranker, belief_encoder, environment,
            args.episodes, args.quality, args.save_raw_obs
        )

        # ä¿å­˜æ•°æ®
        output_dir = os.path.join(collector.output_dir, args.env_name)
        Path(output_dir).mkdir(parents=True, exist_ok=True)

        data_path = os.path.join(output_dir, f'{args.quality}_data.pkl')
        dataset.save(data_path, format='pickle')

        # ä¿å­˜D4RLæ ¼å¼
        d4rl_path = os.path.join(output_dir, f'{args.quality}_data_d4rl.npz')
        dataset.save(d4rl_path, format='d4rl')

        print(f"âœ… {args.env_name} {args.quality}æ•°æ®å·²ä¿å­˜:")
        print(f"  Pickleæ ¼å¼: {data_path}")
        print(f"  D4RLæ ¼å¼: {d4rl_path}")

        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        stats = dataset.get_stats()
        print(f"  æ•°æ®é›†ç»Ÿè®¡:")
        for key, value in stats.items():
            print(f"    {key}: {value}")

        print(f"\nğŸ‰ æ•°æ®æ”¶é›†å®Œæˆ!")
        print(f"æ•°æ®ä¿å­˜åœ¨: {output_dir}")

if __name__ == "__main__":
    main()
