#!/usr/bin/env python3
"""
æ¨¡å‹åŠ è½½å™¨
ç”¨äºåŠ è½½è®­ç»ƒå¥½çš„GeMSæ¨¡å‹è¿›è¡Œæ•°æ®æ”¶é›†
"""
import torch
import sys
import os
from pathlib import Path
from typing import Dict, Any, Optional, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„ - ä»core/å‘ä¸Š4çº§åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼Œç„¶åè¿›å…¥src/
# core/ -> offline_data_collection/ -> data_collection/ -> src/ -> offline-slate-rl/
OFFLINE_DATA_COLLECTION_DIR = Path(__file__).resolve().parent.parent
PROJECT_ROOT = OFFLINE_DATA_COLLECTION_DIR.parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT / "src"))

from agents.online import SAC, SlateQ, REINFORCE, WolpertingerSAC
from belief_encoders.gru_belief import GRUBelief
from rankers.gems.rankers import GeMS, TopKRanker, kHeadArgmaxRanker
from rankers.gems.item_embeddings import ItemEmbeddings, MFEmbeddings
from common.online.argument_parser import MyParser

class ModelLoader:
    """æ¨¡å‹åŠ è½½å™¨"""
    
    def __init__(self, models_dir: str = None):
        # åŠ¨æ€è®¾ç½®é»˜è®¤æ¨¡å‹ç›®å½•
        if models_dir is None:
            project_root = Path(__file__).resolve().parent.parent
            models_dir = str(project_root / "offline_data_collection" / "best_models_for_data_collection")
        self.models_dir = models_dir
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # ç¯å¢ƒé…ç½®
        self.env_configs = {
            'diffuse_topdown': {
                'num_items': 1000,
                'rec_size': 10,
                'num_topics': 10,
                'topic_size': 2,
                'item_embedd_dim': 20,
                'belief_state_dim': 20,
                'env_embedds': 'item_embeddings_diffuse.pt'
            },
            'diffuse_mix': {
                'num_items': 1000,
                'rec_size': 10,
                'num_topics': 10,
                'topic_size': 2,
                'item_embedd_dim': 20,
                'belief_state_dim': 20,
                'env_embedds': 'item_embeddings_diffuse.pt'
            },
            'diffuse_divpen': {
                'num_items': 1000,
                'rec_size': 10,
                'num_topics': 10,
                'topic_size': 2,
                'item_embedd_dim': 20,
                'belief_state_dim': 20,
                'env_embedds': 'item_embeddings_diffuse.pt'
            },
            'focused_topdown': {
                'num_items': 1000,
                'rec_size': 10,
                'num_topics': 10,
                'topic_size': 2,
                'item_embedd_dim': 20,
                'belief_state_dim': 20,
                'env_embedds': 'item_embeddings_focused.pt'
            },
            'focused_mix': {
                'num_items': 1000,
                'rec_size': 10,
                'num_topics': 10,
                'topic_size': 2,
                'item_embedd_dim': 20,
                'belief_state_dim': 20,
                'env_embedds': 'item_embeddings_focused.pt'
            },
            'focused_divpen': {
                'num_items': 1000,
                'rec_size': 10,
                'num_topics': 10,
                'topic_size': 2,
                'item_embedd_dim': 20,
                'belief_state_dim': 20,
                'env_embedds': 'item_embeddings_focused.pt'
            }
        }
    
    def load_item_embeddings(self, env_name: str, embedding_type: str = "ideal") -> ItemEmbeddings:
        """
        åŠ è½½ç‰©å“embeddings
        
        Args:
            env_name: ç¯å¢ƒåç§°
            embedding_type: embeddingç±»å‹ (ideal, scratch, mf)
            
        Returns:
            item_embeddings: ItemEmbeddingså¯¹è±¡
        """
        config = self.env_configs[env_name]
        
        if embedding_type == "ideal":
            # åŠ è½½é¢„è®­ç»ƒçš„ideal embeddings - ä½¿ç”¨ç»Ÿä¸€è·¯å¾„é…ç½®
            project_root = Path(__file__).resolve().parent.parent.parent.parent.parent
            sys.path.insert(0, str(project_root / "config"))
            from paths import get_embeddings_path
            embeddings_path = str(get_embeddings_path(config['env_embedds']))
            if os.path.exists(embeddings_path):
                embeddings_tensor = torch.load(embeddings_path, map_location=self.device)
                item_embeddings = ItemEmbeddings(
                    num_items=config['num_items'],
                    item_embedd_dim=config['item_embedd_dim'],
                    device=self.device
                )
                item_embeddings.embedd.weight.data = embeddings_tensor
                print(f"âœ… æˆåŠŸåŠ è½½ideal embeddings: {embeddings_path}")
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°ideal embeddingsæ–‡ä»¶ {embeddings_path}, ä½¿ç”¨éšæœºåˆå§‹åŒ–")
                item_embeddings = ItemEmbeddings(
                    num_items=config['num_items'],
                    item_embedd_dim=config['item_embedd_dim'],
                    device=self.device
                )
        
        elif embedding_type == "scratch":
            # éšæœºåˆå§‹åŒ–
            item_embeddings = ItemEmbeddings(
                num_items=config['num_items'],
                item_embedd_dim=config['item_embedd_dim'],
                device=self.device
            )
        
        elif embedding_type == "mf":
            # åŠ è½½MF embeddings - ä½¿ç”¨ç»Ÿä¸€è·¯å¾„é…ç½®
            project_root = Path(__file__).resolve().parent.parent.parent.parent.parent
            sys.path.insert(0, str(project_root / "config"))
            from paths import get_mf_embeddings_path
            mf_path = str(get_mf_embeddings_path(f"{env_name}_moving_env"))
            if os.path.exists(mf_path):
                item_embeddings = MFEmbeddings(
                    num_items=config['num_items'],
                    item_embedd_dim=config['item_embedd_dim'],
                    device=self.device
                )
                # åŠ è½½MFæƒé‡
                mf_checkpoint = torch.load(mf_path, map_location=self.device)
                item_embeddings.load_state_dict(mf_checkpoint)
            else:
                print(f"è­¦å‘Š: æœªæ‰¾åˆ°MF embeddingsæ–‡ä»¶ {mf_path}, ä½¿ç”¨éšæœºåˆå§‹åŒ–")
                item_embeddings = ItemEmbeddings(
                    num_items=config['num_items'],
                    item_embedd_dim=config['item_embedd_dim'],
                    device=self.device
                )
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„embeddingç±»å‹: {embedding_type}")
        
        return item_embeddings
    
    def load_ranker(self, env_name: str) -> Any:
        """
        åˆ›å»º GeMS ranker ç»“æ„ï¼ˆç”¨äº SAC+GeMS æ¨¡å‹åŠ è½½ï¼‰

        æ³¨æ„ï¼š
            - æ­¤æ–¹æ³•åªåˆ›å»º ranker ç»“æ„ï¼Œä¸åŠ è½½æƒé‡
            - æƒé‡å°†ä» SAC+GeMS checkpoint ä¸­åŠ è½½
            - ä¸å†æ”¯æŒå•ç‹¬åŠ è½½ GeMS checkpoint
            - ä¸å†æ”¯æŒ TopK ranker

        Args:
            env_name: ç¯å¢ƒåç§°

        Returns:
            ranker: GeMS ranker å¯¹è±¡ï¼ˆæœªåŠ è½½æƒé‡ï¼‰
        """
        config = self.env_configs[env_name]

        # åˆ›å»º scratch embeddingsï¼ˆæƒé‡å°†ä» checkpoint åŠ è½½ï¼‰
        item_embeddings = self.load_item_embeddings(env_name, "scratch")

        ranker = GeMS(
            item_embeddings=item_embeddings,
            item_embedd_dim=config['item_embedd_dim'],
            rec_size=config['rec_size'],
            num_items=config['num_items'],
            latent_dim=32,
            hidden_layers_infer=[512, 256],
            hidden_layers_decoder=[256, 512],
            device=self.device,
            lambda_click=0.5,  # å ä½å€¼ï¼Œå°†ä» checkpoint åŠ è½½
            lambda_KL=0.5,
            lambda_prior=0.0,
            ranker_lr=0.001,
            fixed_embedds=False,
            ranker_sample=False
        )

        return ranker

    def load_model(self, env_name: str,
                   checkpoint_path: Optional[str] = None,
                   quality: str = "expert",
                   beta: float = 1.0,
                   lambda_click: float = 0.5) -> Tuple[Any, Any, Any]:
        """
        åŠ è½½å®Œæ•´çš„æ¨¡å‹ï¼ˆload_agent çš„åˆ«åæ–¹æ³•ï¼‰

        å‚æ•°è¯´æ˜è¯·å‚è€ƒ load_agent() æ–¹æ³•
        """
        return self.load_agent(env_name, checkpoint_path, quality, beta, lambda_click)
    
    def load_agent(self, env_name: str,
                   checkpoint_path: Optional[str] = None,
                   quality: str = "expert",
                   beta: float = 1.0,
                   lambda_click: float = 0.5) -> Tuple[Any, Any, Any]:
        """
        åŠ è½½å®Œæ•´çš„ SAC+GeMS æ¨¡å‹ï¼ˆç”¨äºç¦»çº¿æ•°æ®æ”¶é›†ï¼‰

        Args:
            env_name: ç¯å¢ƒåç§° (diffuse_topdown, diffuse_mix, diffuse_divpen,
                               focused_topdown, focused_mix, focused_divpen)
            checkpoint_path: å¯é€‰ï¼ŒæŒ‡å®š checkpoint æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
                            å¦‚æœä¸æŒ‡å®šï¼Œå°†ä» model_info.json è‡ªåŠ¨æŸ¥æ‰¾åŒ¹é…çš„æ¨¡å‹
            quality: æ¨¡å‹è´¨é‡çº§åˆ« (expert, medium, random)
                    ä»…åœ¨ checkpoint_path=None æ—¶ä½¿ç”¨
            beta: GeMS beta å‚æ•°ï¼Œä»…åœ¨ checkpoint_path=None æ—¶ä½¿ç”¨
            lambda_click: GeMS lambda_click å‚æ•°ï¼Œä»…åœ¨ checkpoint_path=None æ—¶ä½¿ç”¨

        Returns:
            (agent, ranker, belief_encoder): æ¨¡å‹ç»„ä»¶

        æ³¨æ„ï¼š
            - åªæ”¯æŒåŠ è½½ SAC+GeMS æ¨¡å‹ï¼ˆagent_type=SAC, ranker_type=GeMSï¼‰
            - embeddings å’Œæ‰€æœ‰æƒé‡éƒ½ä» checkpoint åŠ è½½ï¼Œä¸æ”¯æŒéšæœºåˆå§‹åŒ–
            - å¦‚æœæŒ‡å®š checkpoint_pathï¼Œå°†å¿½ç•¥ quality/beta/lambda_click å‚æ•°

        ä½¿ç”¨ç¤ºä¾‹ï¼š
            # è‡ªåŠ¨åŠ è½½ï¼ˆä» model_info.jsonï¼‰
            agent, ranker, belief = loader.load_agent("diffuse_topdown")

            # æŒ‡å®šå‚æ•°è‡ªåŠ¨åŠ è½½
            agent, ranker, belief = loader.load_agent(
                "focused_topdown", quality="expert", beta=0.5, lambda_click=0.2
            )

            # æŒ‡å®šå®Œæ•´è·¯å¾„ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            agent, ranker, belief = loader.load_agent(
                "diffuse_topdown",
                checkpoint_path="/path/to/SAC+GeMS_xxx.ckpt"
            )
        """
        config = self.env_configs[env_name]

        # ============================================================================
        # ç¬¬1æ­¥ï¼šç¡®å®š checkpoint è·¯å¾„
        # ============================================================================

        # å¦‚æœæ²¡æœ‰æŒ‡å®š checkpoint_pathï¼Œä» model_info.json è‡ªåŠ¨æŸ¥æ‰¾
        if checkpoint_path is None:
            checkpoint_path = self._get_checkpoint_from_config(
                env_name, quality, beta, lambda_click
            )
            print(f"ğŸ“‹ ä»é…ç½®æ–‡ä»¶è‡ªåŠ¨é€‰æ‹©æ¨¡å‹:")
            print(f"   ç¯å¢ƒ: {env_name}")
            print(f"   è´¨é‡: {quality}")
            print(f"   å‚æ•°: beta={beta}, lambda_click={lambda_click}")
            print(f"   æ–‡ä»¶: {os.path.basename(checkpoint_path)}")
        else:
            print(f"ğŸ“¦ ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹: {os.path.basename(checkpoint_path)}")

        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(checkpoint_path):
            raise FileNotFoundError(
                f"Checkpoint æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}\n"
                f"è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œæˆ–æ£€æŸ¥ model_info.json é…ç½®"
            )

        print(f"âœ… Checkpoint æ–‡ä»¶å­˜åœ¨ï¼Œå¼€å§‹åŠ è½½...")

        # ============================================================================
        # ç¬¬2æ­¥ï¼šåˆ›å»ºæ¨¡å‹ç»„ä»¶ç»“æ„
        # ============================================================================

        print(f"\nğŸ”§ åˆ›å»ºæ¨¡å‹ç»„ä»¶ç»“æ„...")

        # 2.1 åˆ›å»º Belief Encoderï¼ˆä½¿ç”¨ scratch embeddingsï¼Œæƒé‡å°†ä» checkpoint åŠ è½½ï¼‰
        input_dim = config['rec_size'] * (config['item_embedd_dim'] + 1)  # 10 * (20 + 1) = 210
        belief_item_embeds = self.load_item_embeddings(env_name, "scratch")

        belief_encoder = GRUBelief(
            hidden_dim=config['belief_state_dim'],      # 20
            input_dim=input_dim,                        # 210
            item_embeddings=belief_item_embeds,
            belief_state_dim=config['belief_state_dim'],# 20
            item_embedd_dim=config['item_embedd_dim'],  # 20
            rec_size=config['rec_size'],                # 10
            ranker=True,
            device=self.device,
            belief_lr=0.001,
            hidden_layers_reduction=[256],
            beliefs=['actor', 'critic']
        )
        print(f"  âœ… Belief Encoder ç»“æ„å·²åˆ›å»º")

        # 2.2 åˆ›å»º Rankerï¼ˆä½¿ç”¨ scratch embeddingsï¼Œæƒé‡å°†ä» checkpoint åŠ è½½ï¼‰
        ranker = self.load_ranker(env_name)
        print(f"  âœ… GeMS Ranker ç»“æ„å·²åˆ›å»º")

        # 2.3 åˆ›å»º SAC Agent
        action_dim = 32  # GeMS latent_dim
        agent = SAC(
            belief=belief_encoder,
            ranker=ranker,
            state_dim=config['belief_state_dim'],  # 20
            action_dim=action_dim,   # 32 for GeMS
            num_actions=1,  # è¿ç»­SACæ¨¡å¼
            device=self.device,
            random_steps=1000,
            verbose=False,
            q_lr=0.001,
            pi_lr=0.003,
            gamma=0.8,
            tau=0.002,
            alpha=0.2,
            l2_reg=0.0,
            auto_entropy=True,
            alpha_lr=0.001,
            epsilon_start=1.0,
            epsilon_end=0.01,
            epsilon_decay=0.995,
            gradient_steps=1,
            hidden_layers_qnet=[256],
            hidden_layers_pinet=[256],
            target_update_frequency=1
        )
        print(f"  âœ… SAC Agent ç»“æ„å·²åˆ›å»º")

        # ============================================================================
        # ç¬¬3æ­¥ï¼šåŠ è½½ checkpoint å¹¶éªŒè¯
        # ============================================================================

        print(f"\nğŸ“¦ åŠ è½½ checkpoint...")

        try:
            checkpoint = torch.load(checkpoint_path, map_location=self.device)
            state_dict = checkpoint['state_dict']
            print(f"  âœ… Checkpoint åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(state_dict)} ä¸ªé”®")
        except Exception as e:
            raise RuntimeError(f"åŠ è½½ checkpoint å¤±è´¥: {e}")

        # éªŒè¯å¿…è¦çš„ç»„ä»¶æ˜¯å¦å­˜åœ¨
        print(f"\nğŸ” éªŒè¯ checkpoint å®Œæ•´æ€§...")
        required_components = {
            'ranker.item_embeddings.weight': 'Ranker embeddings',
            'belief.ranker.item_embeddings.weight': 'Belief embeddings',
            'PolicyNet.0.weight': 'Policy network',
            'QNet.0.weight': 'Q network'
        }

        missing_components = []
        for key, name in required_components.items():
            if key not in state_dict:
                missing_components.append(f"{name} ({key})")

        if missing_components:
            raise ValueError(
                f"âŒ Checkpoint ä¸å®Œæ•´ï¼Œç¼ºå°‘ä»¥ä¸‹ç»„ä»¶:\n" +
                "\n".join(f"     - {c}" for c in missing_components) +
                f"\n\nè¿™å¯èƒ½ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ SAC+GeMS checkpoint æ–‡ä»¶ã€‚"
            )

        print(f"  âœ… Checkpoint å®Œæ•´æ€§éªŒè¯é€šè¿‡")

        # è¿‡æ»¤è®­ç»ƒçŠ¶æ€ç›¸å…³çš„é”®
        model_keys_only = {
            k: v for k, v in state_dict.items()
            if not k.startswith(('q_optimizer.', 'pi_optimizer.', 'alpha_optimizer.',
                                'global_step', 'epoch'))
        }
        print(f"  â„¹ï¸  è¿‡æ»¤åä¿ç•™ {len(model_keys_only)} ä¸ªæ¨¡å‹æƒé‡é”®")

        # ============================================================================
        # ç¬¬4æ­¥ï¼šåŠ è½½æƒé‡åˆ° Agent
        # ============================================================================

        print(f"\nğŸ”„ åŠ è½½æƒé‡åˆ°æ¨¡å‹...")

        try:
            load_result = agent.load_state_dict(model_keys_only, strict=False)
        except Exception as e:
            raise RuntimeError(f"åŠ è½½æƒé‡å¤±è´¥: {e}")

        # æ£€æŸ¥æ ¸å¿ƒç»„ä»¶æ˜¯å¦æˆåŠŸåŠ è½½
        core_missing = [k for k in load_result.missing_keys
                        if k.startswith(('ranker.', 'belief.', 'QNet', 'PolicyNet'))]

        if core_missing:
            raise RuntimeError(
                f"âŒ æ ¸å¿ƒç»„ä»¶åŠ è½½å¤±è´¥ï¼Œç¼ºå¤± {len(core_missing)} ä¸ªé”®:\n" +
                "\n".join(f"     - {k}" for k in core_missing[:10]) +
                ("\n     ..." if len(core_missing) > 10 else "")
            )

        print(f"  âœ… Agent æƒé‡åŠ è½½æˆåŠŸ")
        print(f"  âœ… Ranker æƒé‡åŠ è½½æˆåŠŸï¼ˆåŒ…å« embeddingsï¼‰")
        print(f"  âœ… Belief æƒé‡åŠ è½½æˆåŠŸï¼ˆåŒ…å« embeddingsï¼‰")

        # éªŒè¯ embeddings æ˜¯å¦æˆåŠŸåŠ è½½ï¼ˆæ–¹æ¡ˆAçš„å…³é”®éªŒè¯ï¼‰
        if 'ranker.item_embeddings.weight' in state_dict:
            ranker_embed_shape = state_dict['ranker.item_embeddings.weight'].shape
            print(f"  âœ… Ranker embeddings å·²ä» checkpoint åŠ è½½: {ranker_embed_shape}")
        else:
            raise RuntimeError("âŒ Checkpoint ä¸­æ²¡æœ‰ ranker embeddingsï¼Œæ— æ³•åŠ è½½")

        if 'belief.ranker.item_embeddings.weight' in state_dict:
            belief_embed_shape = state_dict['belief.ranker.item_embeddings.weight'].shape
            print(f"  âœ… Belief embeddings å·²ä» checkpoint åŠ è½½: {belief_embed_shape}")
        else:
            raise RuntimeError("âŒ Checkpoint ä¸­æ²¡æœ‰ belief embeddingsï¼Œæ— æ³•åŠ è½½")

        # ============================================================================
        # ç¬¬5æ­¥ï¼šåŠ è½½ action_bounds
        # ============================================================================

        print(f"\nğŸ¯ åŠ è½½ action bounds...")

        if 'action_center' in state_dict and 'action_scale' in state_dict:
            agent.action_center = state_dict['action_center'].to(self.device)
            agent.action_scale = state_dict['action_scale'].to(self.device)
            print(f"  âœ… Action bounds å·²ä» checkpoint åŠ è½½")
            print(f"     Center shape: {agent.action_center.shape}")
            print(f"     Scale shape: {agent.action_scale.shape}")

        else:
            # å¦‚æœ checkpoint ä¸­æ²¡æœ‰ï¼Œä»æ•°æ®é›†åŠ¨æ€è®¡ç®—
            print(f"  âš ï¸  Checkpoint ä¸­æ²¡æœ‰ action_boundsï¼Œå°è¯•ä»æ•°æ®é›†è®¡ç®—...")

            # ä½¿ç”¨ç»Ÿä¸€è·¯å¾„é…ç½®è·å–æ•°æ®é›†è·¯å¾„
            sys.path.insert(0, str(PROJECT_ROOT / "config"))
            from paths import get_online_dataset_path
            dataset_path = get_online_dataset_path(env_name)

            if os.path.exists(dataset_path):
                print(f"  ğŸ“Š æ­£åœ¨ä»æ•°æ®é›†è®¡ç®—ç²¾ç¡® Action Bounds: {dataset_path}")
                center, scale = ranker.get_action_bounds(str(dataset_path), batch_size=10)

                agent.action_center = center.to(self.device)
                agent.action_scale = scale.to(self.device)

                print(f"  âœ… ç²¾ç¡® Bounds å·²åº”ç”¨!")
                print(f"     Scale Mean: {scale.mean().item():.4f} (åº”æ¥è¿‘ 3.18)")
                print(f"     Scale Std:  {scale.std().item():.4f}")
            else:
                print(f"  âš ï¸ æœªæ‰¾åˆ°æ•°æ®é›† {dataset_path}ï¼Œå›é€€åˆ°é»˜è®¤å€¼ 3.0 (æ€§èƒ½å¯èƒ½å—æŸ)")
                agent.action_center = torch.zeros(action_dim, device=self.device)
                agent.action_scale = 3.0 * torch.ones(action_dim, device=self.device)

        # ============================================================================
        # ç¬¬6æ­¥ï¼šè®¾ç½®è¯„ä¼°æ¨¡å¼å¹¶ç§»åˆ°è®¾å¤‡
        # ============================================================================

        print(f"\nğŸš€ æœ€ç»ˆè®¾ç½®...")

        agent.eval()
        agent = agent.to(self.device)
        ranker.eval()
        ranker = ranker.to(self.device)
        belief_encoder.eval()
        belief_encoder = belief_encoder.to(self.device)

        print(f"  âœ… æ‰€æœ‰ç»„ä»¶å·²è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼")
        print(f"  âœ… æ‰€æœ‰ç»„ä»¶å·²ç§»åˆ°è®¾å¤‡: {self.device}")

        print(f"\n{'='*80}")
        print(f"âœ… SAC+GeMS æ¨¡å‹åŠ è½½å®Œæˆ!")
        print(f"{'='*80}\n")

        return agent, ranker, belief_encoder

    def _get_checkpoint_from_config(self, env_name: str, quality: str,
                                    beta: float, lambda_click: float) -> str:
        """
        ä» model_info.json è·å– checkpoint è·¯å¾„ï¼ˆV2ç®€åŒ–ç‰ˆæœ¬ï¼‰

        Args:
            env_name: ç¯å¢ƒåç§°
            quality: æ¨¡å‹è´¨é‡çº§åˆ« (expert, medium)
            beta: GeMS beta å‚æ•°ï¼ˆV2ä¸­å·²åœ¨JSONé…ç½®ï¼Œæ­¤å‚æ•°ä»…ç”¨äºéªŒè¯ï¼‰
            lambda_click: GeMS lambda_click å‚æ•°ï¼ˆV2ä¸­å·²åœ¨JSONé…ç½®ï¼Œæ­¤å‚æ•°ä»…ç”¨äºéªŒè¯ï¼‰

        Returns:
            checkpoint_path: checkpoint æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        """
        import json

        # æ„å»º model_info.json è·¯å¾„
        models_base_dir = Path(__file__).resolve().parent.parent / "models"
        config_path = models_base_dir / quality / "model_info.json"

        if not config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")

        # è¯»å–V2æ‰å¹³åŒ–é…ç½®
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)

        # ç›´æ¥è¯»å–æ¨¡å‹ä¿¡æ¯ï¼ˆæ— éœ€å‚æ•°åŒ¹é…ï¼‰
        if env_name not in config['models']:
            available_envs = list(config['models'].keys())
            raise ValueError(f"ç¯å¢ƒ '{env_name}' ä¸åœ¨é…ç½®ä¸­ã€‚å¯ç”¨ç¯å¢ƒ: {available_envs}")

        model_info = config['models'][env_name]

        # æ„å»ºå®Œæ•´è·¯å¾„ï¼ˆä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼‰
        checkpoint_path = models_base_dir / quality / model_info['filename']

        if not checkpoint_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")

        print(f"ğŸ“¦ ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹: {Path(model_info['filename']).name}")
        return str(checkpoint_path)

    def load_diffuse_models(self, quality_level: str = "expert") -> Dict[str, Tuple[Any, Any, Any]]:
        """
        åŠ è½½æ‰€æœ‰diffuseç¯å¢ƒçš„SAC+GeMSæ¨¡å‹ï¼ˆV2é‡æ„ç‰ˆæœ¬ï¼‰

        Args:
            quality_level: æ¨¡å‹è´¨é‡çº§åˆ« ("expert", "medium")
                - expert: 100kæ­¥è®­ç»ƒçš„é«˜è´¨é‡æ¨¡å‹
                - medium: 50kæ­¥è®­ç»ƒçš„ä¸­ç­‰è´¨é‡æ¨¡å‹

        Returns:
            models: {env_name: (agent, ranker, belief_encoder)}
        """
        models = {}
        diffuse_envs = ['diffuse_topdown', 'diffuse_mix', 'diffuse_divpen']

        # æ ¹æ®è´¨é‡çº§åˆ«é€‰æ‹©æ¨¡å‹ç›®å½•
        models_base_dir = Path(__file__).resolve().parent.parent / "models" / quality_level

        # è¯»å–model_info.jsonï¼ˆV2æ‰å¹³åŒ–ç»“æ„ï¼‰
        model_info_path = models_base_dir / "model_info.json"
        import json
        with open(model_info_path, 'r') as f:
            model_config = json.load(f)

        for env_name in diffuse_envs:
            print(f"\nåŠ è½½ {env_name} ç¯å¢ƒçš„ {quality_level} çº§åˆ«æ¨¡å‹...")
            try:
                # ç›´æ¥è¯»å–æ¨¡å‹ä¿¡æ¯ï¼ˆV2æ‰å¹³åŒ–ç»“æ„ï¼‰
                model_info = model_config['models'].get(env_name)
                if not model_info:
                    print(f"âš ï¸ æœªæ‰¾åˆ° {env_name} çš„æ¨¡å‹é…ç½®")
                    continue

                # æå–å‚æ•°ï¼ˆç›´æ¥è®¿é—®ï¼Œæ— éœ€å±‚çº§åˆ¤æ–­ï¼‰
                params = model_info['parameters']
                env_config = model_info['env_config']

                beta = params['beta']
                lambda_click = params['lambda_click']

                print(f"  ä½¿ç”¨å‚æ•°: beta={beta}, lambda_click={lambda_click}")

                # æ„å»ºcheckpointè·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
                checkpoint_path = models_base_dir / model_info['filename']

                # åŠ è½½SAC+GeMSæ¨¡å‹
                agent, ranker, belief_encoder = self.load_agent(
                    env_name=env_name,
                    checkpoint_path=str(checkpoint_path),
                    quality=quality_level,
                    beta=beta,
                    lambda_click=lambda_click
                )

                models[env_name] = (agent, ranker, belief_encoder)
                print(f"âœ… {env_name} SAC+GeMSæ¨¡å‹åŠ è½½æˆåŠŸ")
                print(f"   - AgentåŠ¨ä½œç»´åº¦: {agent.action_dim}")
                print(f"   - Rankerç±»å‹: {type(ranker).__name__}")
                print(f"   - Ranker latent_dim: {ranker.latent_dim if hasattr(ranker, 'latent_dim') else 'N/A'}")
            except Exception as e:
                print(f"âŒ {env_name} SAC+GeMSæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()

        return models

    def load_focused_models(self, quality_level: str = "expert") -> Dict[str, Tuple[Any, Any, Any]]:
        """
        åŠ è½½æ‰€æœ‰focusedç¯å¢ƒçš„SAC+GeMSæ¨¡å‹

        Args:
            quality_level: æ¨¡å‹è´¨é‡çº§åˆ« ("expert", "medium", "random")
                - expert: 10wæ­¥è®­ç»ƒçš„é«˜è´¨é‡æ¨¡å‹
                - medium: 5wæ­¥è®­ç»ƒçš„ä¸­ç­‰è´¨é‡æ¨¡å‹
                - random: éšæœºç­–ç•¥æ¨¡å‹

        Returns:
            models: {env_name: (agent, ranker, belief_encoder)}
        """
        models = {}

        focused_envs = ['focused_topdown', 'focused_mix', 'focused_divpen']

        # æ ¹æ®è´¨é‡çº§åˆ«é€‰æ‹©æ¨¡å‹ç›®å½•
        models_base_dir = Path(__file__).resolve().parent.parent / "models" / quality_level

        for env_name in focused_envs:
            print(f"\nåŠ è½½ {env_name} ç¯å¢ƒçš„ {quality_level} çº§åˆ«æ¨¡å‹...")
            try:
                # ä¸´æ—¶ä¿®æ”¹models_dirä¸ºæŒ‡å®šè´¨é‡çº§åˆ«çš„æ¨¡å‹ç›®å½•
                original_models_dir = self.models_dir
                self.models_dir = str(models_base_dir / "sac_gems_models" / env_name)

                # åŠ è½½SAC+GeMSæ¨¡å‹
                agent, ranker, belief_encoder = self.load_agent(
                    env_name=env_name,
                    quality=quality_level
                )

                # æ¢å¤åŸå§‹models_dir
                self.models_dir = original_models_dir

                models[env_name] = (agent, ranker, belief_encoder)
                print(f"âœ… {env_name} SAC+GeMSæ¨¡å‹åŠ è½½æˆåŠŸ")
                print(f"   - AgentåŠ¨ä½œç»´åº¦: {agent.action_dim}")
                print(f"   - Rankerç±»å‹: {type(ranker).__name__}")
                print(f"   - Ranker latent_dim: {ranker.latent_dim if hasattr(ranker, 'latent_dim') else 'N/A'}")
            except Exception as e:
                print(f"âŒ {env_name} SAC+GeMSæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()

        return models


if __name__ == "__main__":
    # æµ‹è¯•æ¨¡å‹åŠ è½½
    print("æµ‹è¯•æ¨¡å‹åŠ è½½å™¨...")
    
    loader = ModelLoader()
    
    # æµ‹è¯•åŠ è½½å•ä¸ªç¯å¢ƒçš„æ¨¡å‹
    try:
        agent, ranker, belief_encoder = loader.load_agent(
            env_name="diffuse_topdown",
            agent_type="SAC",
            ranker_type="TopK",
            embedding_type="ideal"
        )
        print("âœ… å•ä¸ªæ¨¡å‹åŠ è½½æµ‹è¯•æˆåŠŸ")
        print(f"  Agentç±»å‹: {type(agent).__name__}")
        print(f"  Rankerç±»å‹: {type(ranker).__name__}")
        print(f"  Belief Encoderç±»å‹: {type(belief_encoder).__name__}")
    except Exception as e:
        print(f"âŒ å•ä¸ªæ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•åŠ è½½æ‰€æœ‰diffuseæ¨¡å‹
    try:
        models = loader.load_diffuse_models()
        print(f"\nâœ… æˆåŠŸåŠ è½½ {len(models)} ä¸ªç¯å¢ƒçš„æ¨¡å‹")
        for env_name in models.keys():
            print(f"  - {env_name}")
    except Exception as e:
        print(f"âŒ æ‰¹é‡æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    print("\nâœ… æ¨¡å‹åŠ è½½å™¨æµ‹è¯•å®Œæˆ!")
